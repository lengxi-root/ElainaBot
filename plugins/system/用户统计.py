#!/usr/bin/env python
# -*- coding: utf-8 -*-

from core.plugin.PluginManager import Plugin
from function.db_pool import DatabaseService
import json
import logging
import time
import datetime
from config import LOG_DB_CONFIG
import traceback
from function.httpx_pool import sync_get
from function.database import Database  # å¯¼å…¥Databaseç±»è·å–QQå·
from functools import wraps

# å¯¼å…¥æ—¥å¿—æ•°æ®åº“ç›¸å…³å†…å®¹
try:
    from function.log_db import LogDatabasePool
except ImportError:
    LogDatabasePool = None

# å¯¼å…¥æ’ä»¶ç®¡ç†å™¨
try:
    from core.plugin.PluginManager import PluginManager
except ImportError:
    PluginManager = None

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger('user_stats')

class system_plugin(Plugin):
    # è®¾ç½®æ’ä»¶ä¼˜å…ˆçº§
    priority = 10
    
    # å…¬å…±æ–¹æ³•åŒºåŸŸ
    @staticmethod
    def error_handler(func):
        """ç»Ÿä¸€é”™è¯¯å¤„ç†è£…é¥°å™¨"""
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                # è·å–eventå¯¹è±¡ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªæˆ–ç¬¬äºŒä¸ªå‚æ•°ï¼‰
                event = None
                for arg in args:
                    if hasattr(arg, 'reply') and hasattr(arg, 'user_id'):
                        event = arg
                        break
                
                logger.error(f'{func.__name__}æ‰§è¡Œå¤±è´¥: {e}', exc_info=True)
                if event:
                    event.reply(f'<@{event.user_id}>\nâŒ æ“ä½œå¤±è´¥: {str(e)}')
                else:
                    logger.error(f'æ— æ³•å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œæ‰¾ä¸åˆ°eventå¯¹è±¡')
        return wrapper
    
    @staticmethod
    def mask_id(id_str, mask_char="*"):
        """ç»Ÿä¸€IDè„±æ•å¤„ç†"""
        if not id_str or len(id_str) <= 6:
            return id_str
        return id_str[:3] + mask_char * 4 + id_str[-3:]
    

    
    @staticmethod
    def safe_db_operation(operation_func, *args, **kwargs):
        """å®‰å…¨çš„æ•°æ®åº“æ“ä½œåŒ…è£…"""
        connection = None
        cursor = None
        try:
            result = operation_func(*args, **kwargs)
            return result
        except Exception as e:
            logger.error(f'æ•°æ®åº“æ“ä½œå¤±è´¥: {e}', exc_info=True)
            raise
        finally:
            # æ¸…ç†èµ„æºçš„é€»è¾‘åœ¨å…·ä½“çš„operation_funcä¸­å¤„ç†
            pass
    
    @staticmethod
    def get_regex_handlers():
        return {
            r'^ç”¨æˆ·ç»Ÿè®¡$': {
                'handler': 'get_stats',
                'owner_only': True  # ä»…é™ä¸»äººä½¿ç”¨
            },
            r'^æˆ‘çš„id$': {
                'handler': 'getid',
                'owner_only': False  # æ‰€æœ‰äººå¯ç”¨
            },
            r'^dau(?:\s+)?(\d{4})?$': {
                'handler': 'handle_dau',
                'owner_only': True  # ä»…é™ä¸»äººä½¿ç”¨
            },
            r'^è¡¥å…¨dau$': {
                'handler': 'complete_dau',
                'owner_only': True  # ä»…é™ä¸»äººä½¿ç”¨
            },
            r'^è·å–å…¨éƒ¨æŒ‡ä»¤$': {
                'handler': 'admin_tools',
                'owner_only': True  # ä»…é™ä¸»äººä½¿ç”¨
            },
            r'^å…³äº$': {
                'handler': 'about_info',
                'owner_only': False  # æ‰€æœ‰äººå¯ç”¨
            },
            r'^åˆ é™¤å†å²æ•°æ®$': {
                'handler': 'clean_historical_data',
                'owner_only': True  # ä»…é™ä¸»äººä½¿ç”¨
            }
        }
    
    @staticmethod
    def getid(event):
        """è·å–ç”¨æˆ·IDä¿¡æ¯"""
        try:
            info_parts = [f"<@{event.user_id}>"]
            

            
            # æ·»åŠ åŸºæœ¬ä¿¡æ¯
            info_parts.extend([
                f"ç”¨æˆ·ID: {event.user_id}",
                f"ç¾¤ç»„ID: {event.group_id}"
            ])
            

            
            event.reply("\n".join(info_parts))
        except Exception as e:
            logger.error(f'è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}')
            event.reply(f'<@{event.user_id}>\nâŒ è·å–ä¿¡æ¯å¤±è´¥: {str(e)}')
    

    

    
    
    @classmethod
    def admin_tools(cls, event):
        """ç®¡ç†å·¥å…·ï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æŒ‡ä»¤å’Œç»Ÿè®¡æ•°æ®"""
        # å¦‚æœæ— æ³•å¯¼å…¥PluginManagerï¼Œåˆ™è¿”å›é”™è¯¯
        if PluginManager is None:
            event.reply("æ— æ³•åŠ è½½æ’ä»¶ç®¡ç†å™¨ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            return
            
        try:
            # åˆ›å»ºæ’ä»¶ç®¡ç†å™¨å®ä¾‹å¹¶åŠ è½½æ‰€æœ‰æ’ä»¶
            plugin_manager = PluginManager()
            plugin_manager.load_plugins()
            
            # è·å–æ‰€æœ‰å·²åŠ è½½çš„æ’ä»¶åŠå…¶ä¼˜å…ˆçº§ - ä½¿ç”¨_pluginså­—å…¸
            plugins = list(plugin_manager._plugins.keys())
            
            # æ„å»ºå¤´éƒ¨ä¿¡æ¯
            header = [
                f'<@{event.user_id}>',
                f'ğŸ“‹ æ‰€æœ‰å¯ç”¨æŒ‡ä»¤åˆ—è¡¨',
                f'æ€»æ’ä»¶æ•°: {len(plugins)}ä¸ª'
            ]
            
            # æ„å»ºä»£ç æ¡†å†…å®¹
            code_content = []
            
            # éå†æ‰€æœ‰æ’ä»¶å¹¶æå–å‘½ä»¤
            total_commands = 0
            
            for plugin in plugins:
                plugin_name = plugin.__name__
                priority = plugin_manager._plugins[plugin]  # ä»_pluginså­—å…¸è·å–ä¼˜å…ˆçº§
                handlers = plugin.get_regex_handlers()
                
                if handlers:
                    code_content.append(f'ğŸ”§ æ’ä»¶: {plugin_name} (ä¼˜å…ˆçº§: {priority})')
                    
                    # æ‰€æœ‰å‘½ä»¤ç»Ÿä¸€æ˜¾ç¤ºï¼Œä¸å†åŒºåˆ†æƒé™
                    commands = []
                    
                    for pattern, handler_info in handlers.items():
                        total_commands += 1
                        # æ ¹æ®æ˜¯å¦æ˜¯ä¸»äººå‘½ä»¤æ·»åŠ ä¸åŒçš„emoji
                        if isinstance(handler_info, dict) and handler_info.get('owner_only', False):
                            emoji = "ğŸ‘‘"  # ä¸»äººå‘½ä»¤
                        else:
                            emoji = "ğŸ”¹"  # æ™®é€šå‘½ä»¤
                        
                        # åˆ é™¤æ­£åˆ™è¡¨è¾¾å¼çš„^å’Œ$ç¬¦å·
                        clean_pattern = pattern.replace('^', '').replace('$', '')
                        commands.append(f"  {emoji} {clean_pattern}")
                    
                    # åªæœ‰å‘½ä»¤éç©ºçš„æ’ä»¶æ‰æ·»åŠ åˆ°è¾“å‡ºä¸­
                    if commands:
                        code_content.extend(sorted(commands))
                        code_content.append('-' * 30)
            
            # å‘½ä»¤æ€»ç»“
            code_content.append(f'æ€»å‘½ä»¤æ•°: {total_commands}ä¸ª')
            
            # åˆ›å»ºæœ€ç»ˆæ¶ˆæ¯å†…å®¹ - ä½¿ç”¨ä»£ç æ¡†åŒ…è£¹
            message = '\n'.join(header) + "\n\n```python\n" + '\n'.join(code_content) + "\n```\n"
            
            # å‘é€æ¶ˆæ¯
            event.reply(message)
            
        except Exception as e:
            logger.error(f'ç®¡ç†å·¥å…·æ‰§è¡Œå¤±è´¥: {e}')
            event.reply(f'ç®¡ç†å·¥å…·æš‚æ—¶ä¸å¯ç”¨ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}')
    
    @classmethod
    def handle_dau(cls, event):
        """ç»Ÿä¸€å¤„ç†DAUæŸ¥è¯¢è¯·æ±‚"""
        try:
            # ä»æ­£åˆ™åŒ¹é…ä¸­è·å–æ—¥æœŸå‚æ•°ï¼ˆMMDDæ ¼å¼ï¼Œå¯é€‰ï¼‰
            date_str = event.matches[0] if event.matches and event.matches[0] else None
            
            if date_str:
                # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„DAU
                cls._handle_specific_date_dau(event, date_str)
            else:
                # æŸ¥è¯¢ä»Šæ—¥DAU
                cls._handle_today_dau(event)
                
        except Exception as e:
            logger.error(f'DAUæŸ¥è¯¢å¤±è´¥: {e}')
            event.reply(f'<@{event.user_id}>\nâŒ DAUæŸ¥è¯¢å¤±è´¥: {str(e)}')
    
    @classmethod
    def _handle_specific_date_dau(cls, event, date_str):
        """å¤„ç†ç‰¹å®šæ—¥æœŸçš„DAUæŸ¥è¯¢"""
        if len(date_str) != 4:
            event.reply("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨MMDDæ ¼å¼ï¼Œä¾‹å¦‚ï¼šdau0522è¡¨ç¤º5æœˆ22æ—¥")
            return
            
        # æ„å»ºå®Œæ•´æ—¥æœŸï¼ˆå‡è®¾æ˜¯å½“å‰å¹´ä»½ï¼‰
        current_year = datetime.datetime.now().year
        try:
            month = int(date_str[:2])
            day = int(date_str[2:])
            # éªŒè¯æ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
            query_date = datetime.datetime(current_year, month, day)
            
            # å¦‚æœç”Ÿæˆçš„æ—¥æœŸåœ¨æœªæ¥ï¼Œå¯èƒ½æ˜¯å»å¹´çš„æ—¥æœŸ
            if query_date > datetime.datetime.now():
                query_date = datetime.datetime(current_year - 1, month, day)
                
            # å°†æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDDæ ¼å¼
            formatted_date = query_date.strftime('%Y%m%d')
            # è°ƒç”¨é€šç”¨DAUæŸ¥è¯¢æ–¹æ³•
            cls._get_dau_data(event, formatted_date)
        except ValueError:
            event.reply(f"æ— æ•ˆçš„æ—¥æœŸ: {date_str}ï¼Œè¯·ä½¿ç”¨æœ‰æ•ˆçš„æœˆä»½å’Œæ—¥æœŸ")
    
    @classmethod
    def _handle_today_dau(cls, event):
        """å¤„ç†ä»Šæ—¥DAUæŸ¥è¯¢"""
        # è·å–ä»Šå¤©çš„æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDD
        today = datetime.datetime.now()
        today_str = today.strftime('%Y%m%d')
        
        # è·å–æ˜¨å¤©çš„æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDD
        yesterday = today - datetime.timedelta(days=1)
        yesterday_str = yesterday.strftime('%Y%m%d')
        
        # å½“å‰å°æ—¶å’Œåˆ†é’Ÿï¼Œç”¨äºé™åˆ¶æ˜¨å¤©æ•°æ®æŸ¥è¯¢èŒƒå›´
        current_hour = today.hour
        current_minute = today.minute
        
        # è°ƒç”¨é€šç”¨DAUæŸ¥è¯¢æ–¹æ³•ï¼Œæ·»åŠ å¯¹æ¯”å‚æ•°
        cls._get_dau_data(event, today_str, yesterday_str, current_hour, current_minute)
    
    @classmethod
    def _get_dau_data(cls, event, date_str, yesterday_str=None, current_hour=None, current_minute=None):
        """è·å–ç‰¹å®šæ—¥æœŸçš„DAUç»Ÿè®¡æ•°æ®çš„é€šç”¨æ–¹æ³•
        
        Args:
            event: æ¶ˆæ¯äº‹ä»¶
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYYMMDD
            yesterday_str: æ˜¨å¤©æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸ºYYYYMMDDï¼ˆå¯é€‰ï¼‰
            current_hour: å½“å‰å°æ—¶ï¼ˆå¯é€‰ï¼‰
            current_minute: å½“å‰åˆ†é’Ÿï¼ˆå¯é€‰ï¼‰
        """
        start_time = time.time()
        
        # å°†YYYYMMDDæ ¼å¼è½¬æ¢ä¸ºdatetimeå¯¹è±¡
        target_date = datetime.datetime.strptime(date_str, '%Y%m%d')
        today = datetime.datetime.now().date()
        is_today = target_date.date() == today
        
        # ä¼˜å…ˆå°è¯•ä»æœ¬åœ°æ–‡ä»¶è¯»å–DAUæ•°æ®
        try:
            from function.dau_analytics import get_dau_analytics
            
            dau_analytics = get_dau_analytics()
            dau_data = dau_analytics.load_dau_data(target_date)
            
            if dau_data:
                # ä»æœ¬åœ°æ–‡ä»¶æˆåŠŸè¯»å–åˆ°æ•°æ®
                cls._send_dau_from_file(event, dau_data, target_date, start_time)
                return
                
        except Exception as e:
            logger.warning(f"å°è¯•ä»æœ¬åœ°æ–‡ä»¶è¯»å–DAUæ•°æ®å¤±è´¥: {e}")
        
        # å¦‚æœæ˜¯éä»Šæ—¥æ•°æ®ä¸”æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›æç¤º
        if not is_today:
            display_date = f"{date_str[4:6]}-{date_str[6:8]}"
            
            event.reply(
                f"<@{event.user_id}>\n"
                f"âŒ {display_date} çš„DAUæ•°æ®æœªç”Ÿæˆæˆ–æ— è¯¥æ—¥æœŸæ•°æ®\n"
                f"ğŸ’¡ å¯ä»¥å°è¯•ä½¿ç”¨'è¡¥å…¨dau'å‘½ä»¤è¡¥å…¨DAUè®°å½•"
            )
            return
        
        # å¦‚æœæ˜¯ä»Šæ—¥æ•°æ®ä¸”æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ä»æ•°æ®åº“æŸ¥è¯¢ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        # å¦‚æœæ—¥å¿—æ•°æ®åº“åŠŸèƒ½æœªå¯ç”¨ï¼Œåˆ™è¿”å›æç¤º
        if not LOG_DB_CONFIG.get('enabled', False):
            event.reply("æ—¥å¿—æ•°æ®åº“æœªå¯ç”¨ï¼Œæ— æ³•è·å–DAUç»Ÿè®¡")
            return
            
        # å¦‚æœæ— æ³•å¯¼å…¥LogDatabasePoolï¼Œåˆ™ä½¿ç”¨æ™®é€šæ•°æ®åº“
        if LogDatabasePool is None:
            event.reply("æ— æ³•è®¿é—®æ—¥å¿—æ•°æ®åº“ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return
        
        try:
            # ä½¿ç”¨æ—¥å¿—æ•°æ®åº“è¿æ¥æ± 
            log_db_pool = LogDatabasePool()
            connection = log_db_pool.get_connection()
            
            if not connection:
                event.reply("æ— æ³•è¿æ¥åˆ°æ—¥å¿—æ•°æ®åº“ï¼Œè¯·ç¨åå†è¯•")
                return
            
            cursor = None
            
            try:
                cursor = connection.cursor()
                
                # æ„å»ºæ¶ˆæ¯è¡¨å
                table_name = f"Mlog_{date_str}_message"
                
                # æ£€æŸ¥æ¶ˆæ¯è¡¨æ˜¯å¦å­˜åœ¨
                check_query = f"""
                    SELECT COUNT(*) as count 
                    FROM information_schema.tables 
                    WHERE table_schema = DATABASE() 
                    AND table_name = %s
                """
                
                cursor.execute(check_query, (table_name,))
                result = cursor.fetchone()
                if not result or result['count'] == 0:
                    # å°†YYYYMMDDæ ¼å¼è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
                    display_date = f"{date_str[4:6]}-{date_str[6:8]}"
                    event.reply(f"è¯¥æ—¥æœŸ({display_date})æ— æ¶ˆæ¯è®°å½•")
                    return
                
                # æ—¶é—´é™åˆ¶æ¡ä»¶ - å¦‚æœæœ‰å½“å‰å°æ—¶å’Œåˆ†é’Ÿï¼Œåˆ™é™åˆ¶æŸ¥è¯¢èŒƒå›´
                time_condition = ""
                if current_hour is not None and current_minute is not None:
                    time_limit = f"{current_hour:02d}:{current_minute:02d}:00"
                    time_condition = f" WHERE TIME(timestamp) <= '{time_limit}'"
                
                # æŸ¥è¯¢æ€»æ¶ˆæ¯æ•°
                total_messages_query = f"SELECT COUNT(*) as count FROM {table_name}{time_condition}"
                cursor.execute(total_messages_query)
                total_messages_result = cursor.fetchone()
                total_messages = total_messages_result['count'] if total_messages_result else 0
                
                # æŸ¥è¯¢ä¸åŒç”¨æˆ·æ•°é‡ï¼ˆå»é‡ï¼‰
                unique_users_query = f"SELECT COUNT(DISTINCT user_id) as count FROM {table_name}{time_condition}"
                unique_users_query += " AND user_id IS NOT NULL AND user_id != ''" if time_condition else " WHERE user_id IS NOT NULL AND user_id != ''"
                cursor.execute(unique_users_query)
                unique_users_result = cursor.fetchone()
                unique_users = unique_users_result['count'] if unique_users_result else 0
                
                # æŸ¥è¯¢ä¸åŒç¾¤ç»„æ•°é‡ï¼ˆå»é‡ï¼‰- ä¸åŒ…æ‹¬ç§èŠ
                unique_groups_query = f"SELECT COUNT(DISTINCT group_id) as count FROM {table_name}{time_condition}"
                unique_groups_query += " AND group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''" if time_condition else " WHERE group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''"
                cursor.execute(unique_groups_query)
                unique_groups_result = cursor.fetchone()
                unique_groups = unique_groups_result['count'] if unique_groups_result else 0
                
                # æŸ¥è¯¢ç§èŠæ¶ˆæ¯æ•°é‡
                private_messages_query = f"SELECT COUNT(*) as count FROM {table_name}{time_condition}"
                private_messages_query += " AND group_id = 'c2c'" if time_condition else " WHERE group_id = 'c2c'"
                cursor.execute(private_messages_query)
                private_messages_result = cursor.fetchone()
                private_messages = private_messages_result['count'] if private_messages_result else 0
                
                # è·å–æœ€æ´»è·ƒçš„5ä¸ªç¾¤ç»„
                active_groups_query = f"""
                    SELECT group_id, COUNT(*) as msg_count 
                    FROM {table_name}{time_condition}
                    """
                active_groups_query += " AND group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''" if time_condition else " WHERE group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''"
                active_groups_query += """
                    GROUP BY group_id 
                    ORDER BY msg_count DESC 
                    LIMIT 3
                """
                cursor.execute(active_groups_query)
                active_groups_result = cursor.fetchall()
                
                # è·å–æœ€æ´»è·ƒçš„5ä¸ªç”¨æˆ·
                active_users_query = f"""
                    SELECT user_id, COUNT(*) as msg_count 
                    FROM {table_name}{time_condition}
                    """
                active_users_query += " AND user_id IS NOT NULL AND user_id != ''" if time_condition else " WHERE user_id IS NOT NULL AND user_id != ''"
                active_users_query += """
                    GROUP BY user_id 
                    ORDER BY msg_count DESC 
                    LIMIT 3
                """
                cursor.execute(active_users_query)
                active_users_result = cursor.fetchall()
                
                # æŒ‰å°æ—¶ç»Ÿè®¡æ¶ˆæ¯æ•°é‡
                hourly_stats_query = f"""
                    SELECT HOUR(timestamp) as hour, COUNT(*) as count 
                    FROM {table_name}{time_condition} 
                    GROUP BY HOUR(timestamp) 
                    ORDER BY hour
                """
                cursor.execute(hourly_stats_query)
                hourly_stats_result = cursor.fetchall()
                
                # è®¡ç®—æ¯å°æ—¶çš„æ¶ˆæ¯æ•°
                hours_data = {i: 0 for i in range(24)}
                if hourly_stats_result:
                    for row in hourly_stats_result:
                        hour = row['hour']
                        count = row['count']
                        hours_data[hour] = count
                
                # æŸ¥æ‰¾æœ€æ´»è·ƒçš„å°æ—¶
                most_active_hour = max(hours_data.items(), key=lambda x: x[1]) if hours_data else (0, 0)
                
                # å°†YYYYMMDDæ ¼å¼è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
                display_date = f"{date_str[4:6]}-{date_str[6:8]}"
                
                # å¦‚æœæœ‰æ˜¨å¤©çš„æ—¥æœŸï¼ŒæŸ¥è¯¢æ˜¨å¤©åŒæ—¶æ®µçš„æ•°æ®è¿›è¡Œå¯¹æ¯”
                yesterday_data = None
                if yesterday_str and current_hour is not None and current_minute is not None:
                    yesterday_table = f"Mlog_{yesterday_str}_message"
                    
                    # æ£€æŸ¥æ˜¨å¤©çš„è¡¨æ˜¯å¦å­˜åœ¨
                    cursor.execute(check_query, (yesterday_table,))
                    y_result = cursor.fetchone()
                    
                    if y_result and y_result['count'] > 0:
                        time_limit = f"{current_hour:02d}:{current_minute:02d}:00"
                        y_time_condition = f" WHERE TIME(timestamp) <= '{time_limit}'"
                        
                        # è·å–æ˜¨å¤©åŒæ—¶æ®µçš„åŸºç¡€ç»Ÿè®¡æ•°æ®
                        yesterday_data = {}
                        
                        # æ˜¨å¤©æ€»æ¶ˆæ¯æ•°
                        cursor.execute(f"SELECT COUNT(*) as count FROM {yesterday_table}{y_time_condition}")
                        y_total = cursor.fetchone()
                        yesterday_data['total_messages'] = y_total['count'] if y_total else 0
                        
                        # æ˜¨å¤©æ´»è·ƒç”¨æˆ·æ•°
                        y_users_query = f"SELECT COUNT(DISTINCT user_id) as count FROM {yesterday_table}{y_time_condition}"
                        y_users_query += " AND user_id IS NOT NULL AND user_id != ''"
                        cursor.execute(y_users_query)
                        y_users = cursor.fetchone()
                        yesterday_data['unique_users'] = y_users['count'] if y_users else 0
                        
                        # æ˜¨å¤©æ´»è·ƒç¾¤ç»„æ•°
                        y_groups_query = f"SELECT COUNT(DISTINCT group_id) as count FROM {yesterday_table}{y_time_condition}"
                        y_groups_query += " AND group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''"
                        cursor.execute(y_groups_query)
                        y_groups = cursor.fetchone()
                        yesterday_data['unique_groups'] = y_groups['count'] if y_groups else 0
                        
                        # æ˜¨å¤©ç§èŠæ¶ˆæ¯æ•°
                        y_private_query = f"SELECT COUNT(*) as count FROM {yesterday_table}{y_time_condition}"
                        y_private_query += " AND group_id = 'c2c'"
                        cursor.execute(y_private_query)
                        y_private = cursor.fetchone()
                        yesterday_data['private_messages'] = y_private['count'] if y_private else 0
                
                # æ„å»ºå“åº”ä¿¡æ¯
                info = [
                    f'<@{event.user_id}>',
                    f'ğŸ“Š {display_date} æ´»è·ƒç»Ÿè®¡' + (f' (æˆªè‡³{current_hour:02d}:{current_minute:02d})' if current_hour is not None else '')
                ]
                
                # æ·»åŠ åŸºæœ¬æ•°æ®ä¸æ˜¨å¤©å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰
                if yesterday_data:
                    y_display_date = f"{yesterday_str[4:6]}-{yesterday_str[6:8]}"
                    
                    # ç”¨æˆ·æ•°å¯¹æ¯”
                    user_diff = unique_users - yesterday_data['unique_users']
                    user_change = f"ğŸ”º{user_diff}" if user_diff > 0 else f"ğŸ”»{abs(user_diff)}" if user_diff < 0 else "â–0"
                    info.append(f'ğŸ‘¤ æ´»è·ƒç”¨æˆ·æ•°: {unique_users} ({user_change})')
                    
                    # ç¾¤ç»„æ•°å¯¹æ¯”
                    group_diff = unique_groups - yesterday_data['unique_groups']
                    group_change = f"ğŸ”º{group_diff}" if group_diff > 0 else f"ğŸ”»{abs(group_diff)}" if group_diff < 0 else "â–0"
                    info.append(f'ğŸ‘¥ æ´»è·ƒç¾¤èŠæ•°: {unique_groups} ({group_change})')
                    
                    # æ¶ˆæ¯æ€»æ•°å¯¹æ¯”
                    msg_diff = total_messages - yesterday_data['total_messages']
                    msg_change = f"ğŸ”º{msg_diff}" if msg_diff > 0 else f"ğŸ”»{abs(msg_diff)}" if msg_diff < 0 else "â–0"
                    info.append(f'ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {total_messages} ({msg_change})')
                    
                    # ç§èŠæ¶ˆæ¯å¯¹æ¯”
                    private_diff = private_messages - yesterday_data['private_messages']
                    private_change = f"ğŸ”º{private_diff}" if private_diff > 0 else f"ğŸ”»{abs(private_diff)}" if private_diff < 0 else "â–0"
                    info.append(f'ğŸ“± ç§èŠæ¶ˆæ¯: {private_messages} ({private_change})')
                else:
                    # æ²¡æœ‰æ˜¨å¤©æ•°æ®æ—¶æ˜¾ç¤ºæ™®é€šæ ¼å¼
                    info.append(f'ğŸ‘¤ æ´»è·ƒç”¨æˆ·æ•°: {unique_users}')
                    info.append(f'ğŸ‘¥ æ´»è·ƒç¾¤èŠæ•°: {unique_groups}')
                    info.append(f'ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {total_messages}')
                    info.append(f'ğŸ“± ç§èŠæ¶ˆæ¯: {private_messages}')
                
                info.append(f'â° æœ€æ´»è·ƒæ—¶æ®µ: {most_active_hour[0]}ç‚¹ ({most_active_hour[1]})')
                
                # æ·»åŠ æœ€æ´»è·ƒç¾¤ç»„ä¿¡æ¯
                if active_groups_result:
                    info.append('ğŸ” æœ€æ´»è·ƒç¾¤ç»„:')
                    idx = 1
                    for group in active_groups_result:
                        group_id = group['group_id']
                        if not group_id:
                            continue  # è·³è¿‡ç©º/None
                        masked_group_id = system_plugin.mask_id(group_id)
                        info.append(f"  {idx}. {masked_group_id} ({group['msg_count']}æ¡)")
                        idx += 1
                
                # æ·»åŠ æœ€æ´»è·ƒç”¨æˆ·ä¿¡æ¯
                if active_users_result:
                    info.append('ğŸ‘‘ æœ€æ´»è·ƒç”¨æˆ·:')
                    idx = 1
                    for user in active_users_result:
                        user_id = user['user_id']
                        if not user_id:
                            continue  # è·³è¿‡ç©º/None
                        masked_user_id = system_plugin.mask_id(user_id)
                        info.append(f"  {idx}. {masked_user_id} ({user['msg_count']}æ¡)")
                        idx += 1
                
                # è®¡ç®—æŸ¥è¯¢è€—æ—¶
                query_time = round((time.time() - start_time) * 1000)
                info.append(f'ğŸ•’ æŸ¥è¯¢è€—æ—¶: {query_time}ms')
                info.append(f'ğŸ“ æ•°æ®æº: å®æ—¶æ•°æ®åº“æŸ¥è¯¢')
                
                # å‘é€æ¶ˆæ¯
                event.reply('\n'.join(info))
                
            finally:
                # ç¡®ä¿å…³é—­æ¸¸æ ‡å’Œé‡Šæ”¾è¿æ¥
                if cursor:
                    cursor.close()
                if connection:
                    log_db_pool.release_connection(connection)
            
        except Exception as e:
            logger.error(f'è·å–DAUç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}')
            event.reply(f'DAUç»Ÿè®¡æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}')
    
    @classmethod
    def _send_dau_from_file(cls, event, dau_data, target_date, start_time):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½DAUæ•°æ®å¹¶å‘é€"""
        try:
            # è·å–æ¶ˆæ¯ç»Ÿè®¡æ•°æ®
            msg_stats = dau_data.get('message_stats', {})
            
            info = [
                f'<@{event.user_id}>',
                f'ğŸ“Š {target_date.strftime("%m-%d")} æ´»è·ƒç»Ÿè®¡'
            ]
            
            # æ·»åŠ åŸºæœ¬æ•°æ®
            info.append(f'ğŸ‘¤ æ´»è·ƒç”¨æˆ·æ•°: {msg_stats.get("active_users", 0)}')
            info.append(f'ğŸ‘¥ æ´»è·ƒç¾¤èŠæ•°: {msg_stats.get("active_groups", 0)}')
            info.append(f'ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {msg_stats.get("total_messages", 0)}')
            info.append(f'ğŸ“± ç§èŠæ¶ˆæ¯: {msg_stats.get("private_messages", 0)}')
            
            # æ·»åŠ æœ€æ´»è·ƒæ—¶æ®µ
            peak_hour = msg_stats.get("peak_hour", 0)
            peak_hour_count = msg_stats.get("peak_hour_count", 0)
            info.append(f'â° æœ€æ´»è·ƒæ—¶æ®µ: {peak_hour}ç‚¹ ({peak_hour_count}æ¡)')
            
            # æ·»åŠ æœ€æ´»è·ƒç¾¤ç»„ä¿¡æ¯
            top_groups = msg_stats.get("top_groups", [])
            if top_groups:
                info.append('ğŸ” æœ€æ´»è·ƒç¾¤ç»„:')
                idx = 1
                for group in top_groups[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    group_id = group.get("group_id", "")
                    if not group_id:
                        continue  # è·³è¿‡ç©º/None
                    masked_group_id = system_plugin.mask_id(group_id)
                    info.append(f"  {idx}. {masked_group_id} ({group.get('message_count', 0)}æ¡)")
                    idx += 1
            
            # æ·»åŠ æœ€æ´»è·ƒç”¨æˆ·ä¿¡æ¯
            top_users = msg_stats.get("top_users", [])
            if top_users:
                info.append('ğŸ‘‘ æœ€æ´»è·ƒç”¨æˆ·:')
                idx = 1
                for user in top_users[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    user_id = user.get("user_id", "")
                    if not user_id:
                        continue  # è·³è¿‡ç©º/None
                    masked_user_id = system_plugin.mask_id(user_id)
                    info.append(f"  {idx}. {masked_user_id} ({user.get('message_count', 0)}æ¡)")
                    idx += 1
            
            # è®¡ç®—æŸ¥è¯¢è€—æ—¶
            query_time = round((time.time() - start_time) * 1000)
            info.append(f'ğŸ•’ æŸ¥è¯¢è€—æ—¶: {query_time}ms')
            info.append(f'ğŸ“ æ•°æ®æº: æœ¬åœ°æ–‡ä»¶')
            
            # æ·»åŠ ç”Ÿæˆæ—¶é—´ä¿¡æ¯
            if dau_data.get('generated_at'):
                try:
                    gen_time = datetime.datetime.fromisoformat(dau_data['generated_at'].replace('Z', '+00:00'))
                    info.append(f'ğŸ•’ æ•°æ®ç”Ÿæˆæ—¶é—´: {gen_time.strftime("%m-%d %H:%M")}')
                except:
                    pass
            
            # å‘é€æ¶ˆæ¯
            event.reply('\n'.join(info))
            
        except Exception as e:
            logger.error(f"å‘é€DAUæ–‡ä»¶æ•°æ®å¤±è´¥: {e}")
            # å¦‚æœè§£ææ–‡ä»¶æ•°æ®å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹é”™è¯¯æ¶ˆæ¯
            event.reply(f"DAUæ•°æ®æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")
    
    @classmethod
    def _get_query_params(cls):
        """è·å–æ‰€æœ‰æŸ¥è¯¢å‚æ•°"""
        return [
            # åŸºç¡€æŸ¥è¯¢
            ("SELECT COUNT(*) as count FROM M_users", None, False),  # ç”¨æˆ·æ•°é‡
            ("SELECT COUNT(*) as count FROM M_groups", None, False),  # ç¾¤ç»„æ•°é‡
            ("SELECT COUNT(*) as count FROM M_members", None, False),  # ç§èŠç”¨æˆ·æ•°é‡
            # æœ€æ´»è·ƒç¾¤ç»„æŸ¥è¯¢
            ("""
                SELECT group_id, JSON_LENGTH(users) as member_count
                FROM M_groups_users
                ORDER BY member_count DESC
                LIMIT 1
            """, None, False),
            # UINç»Ÿè®¡æŸ¥è¯¢ï¼ˆåªä¿ç•™ä¸€ä¸ªå ä½æŸ¥è¯¢ï¼Œå®é™…ä½¿ç”¨å›ºå®šå€¼ï¼‰
            ("SELECT 1 as placeholder", None, False)  # å ä½æŸ¥è¯¢ï¼ŒUINæˆåŠŸæ•°ä½¿ç”¨å›ºå®šå€¼64019
        ]
    
    @classmethod
    def _get_group_info_params(cls, group_id):
        """è·å–æŒ‡å®šç¾¤ç»„çš„æŸ¥è¯¢å‚æ•°"""
        return [
            # ç¾¤æˆå‘˜æ•°é‡
            ("SELECT users FROM M_groups_users WHERE group_id = %s", (group_id,), False),
            # è·å–æ‰€æœ‰ç¾¤ç»„æ•°æ®ï¼Œç”¨äºè®¡ç®—æ’å
            ("""
                SELECT group_id, JSON_LENGTH(users) as member_count
                FROM M_groups_users
                ORDER BY member_count DESC
            """, None, True)
        ]
    
    @classmethod
    def _process_result(cls, results):
        """å¤„ç†æŸ¥è¯¢ç»“æœ"""
        user_count = results[0]['count'] if results[0] else 0
        group_count = results[1]['count'] if results[1] else 0
        private_users_count = results[2]['count'] if results[2] else 0
        
        # å¤„ç†æœ€æ´»è·ƒç¾¤ç»„æ•°æ®
        most_active_result = results[3]
        if most_active_result:
            group_id = most_active_result.get('group_id', "æ— æ•°æ®")
            # ä½¿ç”¨ç»Ÿä¸€çš„è„±æ•æ–¹æ³•
            if group_id != "æ— æ•°æ®":
                group_id = system_plugin.mask_id(group_id)
            
            most_active_group = {
                'group_id': group_id,
                'member_count': most_active_result.get('member_count', 0)
            }
        else:
            most_active_group = {'group_id': "æ— æ•°æ®", 'member_count': 0}
            
        # å¤„ç†UINç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨å›ºå®šå€¼ï¼Œä¸ä»æ•°æ®åº“è·å–ï¼‰
        uin_success = 64019  # å›ºå®šå€¼
        
        return {
            'user_count': user_count,
            'group_count': group_count,
            'private_users_count': private_users_count,
            'most_active_group': most_active_group,
            'uin_stats': {
                'success': uin_success
            }
        }
    
    @classmethod
    def _process_group_results(cls, results, group_id):
        """å¤„ç†ç¾¤ç»„ç›¸å…³æŸ¥è¯¢ç»“æœ"""
        # è§£æç¾¤æˆå‘˜æ•°æ®
        group_members = 0
        if results[0] and results[0].get('users'):
            users = results[0]['users']
            if isinstance(users, str):
                users = json.loads(users)
            group_members = len(users)
        
        # è®¡ç®—ç¾¤æ’å
        group_rank = 'N/A'
        if results[1]:
            for i, group in enumerate(results[1], 1):
                if group.get('group_id') == group_id:
                    group_rank = i
                    break
        
        return {
            'member_count': group_members,
            'rank': group_rank
        }
    
    @classmethod
    def get_stats(cls, event):
        """è·å–ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨db_poolçš„å¹¶å‘æŸ¥è¯¢"""
        start_time = time.time()
        
        try:
            db = DatabaseService()
            
            # å‡†å¤‡æ‰€æœ‰æŸ¥è¯¢
            query_params = cls._get_query_params()
            
            # å¦‚æœåœ¨ç¾¤èŠä¸­ï¼Œæ·»åŠ ç¾¤ç»„ç›¸å…³æŸ¥è¯¢
            group_results = None
            if event.group_id:
                group_query_params = cls._get_group_info_params(event.group_id)
                
                # æ‰§è¡Œç¾¤ç»„æŸ¥è¯¢
                group_results = db.execute_concurrent_queries(group_query_params)
            
            # æ‰§è¡ŒåŸºç¡€æŸ¥è¯¢
            results = db.execute_concurrent_queries(query_params)
            
            # å¤„ç†æŸ¥è¯¢ç»“æœ
            stats = cls._process_result(results)
            
            # æ„å»ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            info = [
                f'<@{event.user_id}>',
                f'ğŸ“Š ç»Ÿè®¡ä¿¡æ¯',
            ]
            
            # å¦‚æœåœ¨ç¾¤èŠä¸­ï¼Œé¦–å…ˆæ·»åŠ å½“å‰ç¾¤æˆå‘˜ä¿¡æ¯
            if event.group_id and group_results:
                group_info = cls._process_group_results(group_results, event.group_id)
                info.append(f'ğŸ‘¥ å½“å‰ç¾¤æˆå‘˜: {group_info["member_count"]}')
            
            # æŒ‰ç…§æŒ‡å®šé¡ºåºæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            info.append(f'ğŸ‘¤ å¥½å‹æ€»æ•°é‡: {stats["private_users_count"]}')
            info.append(f'ğŸ‘¥ ç¾¤ç»„æ€»æ•°é‡: {stats["group_count"]}')
            info.append(f'ğŸ‘¥ æ‰€æœ‰ç”¨æˆ·æ€»æ•°é‡: {stats["user_count"]}')
            info.append(f'ğŸ” æœ€å¤§ç¾¤: {stats["most_active_group"]["group_id"]} (ç¾¤å‘˜: {stats["most_active_group"]["member_count"]})')
            
            # æ·»åŠ UINç»Ÿè®¡ä¿¡æ¯ï¼ˆåªæ˜¾ç¤ºæˆåŠŸè·å–æ•°ï¼‰
            info.append(f'âœ… UINæˆåŠŸè·å–: {stats["uin_stats"]["success"]}')
            
            # å¦‚æœåœ¨ç¾¤èŠä¸­ï¼Œæ·»åŠ å½“å‰ç¾¤çš„æ’åä¿¡æ¯
            if event.group_id and group_results:
                group_info = cls._process_group_results(group_results, event.group_id)
                info.append(f'ğŸ“ˆ å½“å‰ç¾¤æ’å: ç¬¬{group_info["rank"]}å')
            
            # ç»Ÿè®¡æŸ¥è¯¢æ—¶é—´
            query_time = round((time.time() - start_time) * 1000)
            info.append(f'ğŸ•’ æŸ¥è¯¢è€—æ—¶: {query_time}ms')
            
            # å‘é€æ¶ˆæ¯
            event.reply('\n'.join(info))
            
        except Exception as e:
            logger.error(f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}')
            event.reply(f'ç»Ÿè®¡æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}')
    
    @staticmethod
    def about_info(event):
        """å…³äºç•Œé¢ï¼Œå±•ç¤ºå†…æ ¸ã€ç‰ˆæœ¬ã€ä½œè€…ç­‰ä¿¡æ¯ï¼ˆä¸ä½¿ç”¨ä»£ç æ¡†ï¼Œæ¯è¡Œå‰åŠ è¡¨æƒ…ï¼‰"""
        # å¯¼å…¥configé…ç½®
        from config import ROBOT_QQ, appid
        
        # å¯¼å…¥PluginManagerè·å–æ’ä»¶å’ŒåŠŸèƒ½æ•°é‡
        try:
            from core.plugin.PluginManager import PluginManager
            
            # åˆ›å»ºæ’ä»¶ç®¡ç†å™¨å®ä¾‹å¹¶åŠ è½½æ‰€æœ‰æ’ä»¶
            plugin_manager = PluginManager()
            plugin_manager.load_plugins()
            
            # è·å–å†…æ ¸æ•°ï¼ˆå·²åŠ è½½çš„æ’ä»¶æ•°ï¼‰
            kernel_count = len(plugin_manager._plugins)
            
            # è·å–åŠŸèƒ½æ•°ï¼ˆå·²æ³¨å†Œçš„å¤„ç†å™¨æ•°ï¼‰
            function_count = len(plugin_manager._regex_handlers)
        except Exception as e:
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            kernel_count = "è·å–å¤±è´¥"
            function_count = "è·å–å¤±è´¥"
            logger.error(f"è·å–æ’ä»¶ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
            
        # è·å–Pythonç‰ˆæœ¬
        import platform
        python_version = platform.python_version()
            
        # æ·»åŠ ç”¨æˆ·@å¹¶ç”¨markdownæ¨ªçº¿åˆ†éš”
        msg = (
f'<@{event.user_id}>å…³äºä¼Šè•¾å¨œ\n___\n'
'ğŸ”Œ è¿æ¥æ–¹å¼: WebHook\n'
f'ğŸ¤– æœºå™¨äººQQ: {ROBOT_QQ}\n'
f'ğŸ†” æœºå™¨äººappid: {appid}\n'
'ğŸš€ å†…æ ¸ç‰ˆæœ¬ï¼šElaina 1.2.3\n'
'ğŸ—ï¸ è¿æ¥Botæ¡†æ¶: Elaina-Bot\n'
f'âš™ï¸ Pythonç‰ˆæœ¬: {python_version}\n'
f'ğŸ’« å·²åŠ è½½å†…æ ¸æ•°: {kernel_count}\n'
f'âš¡ å·²åŠ è½½å¤„ç†å™¨æ•°: {function_count}\n'
'\n\n>Tip:åªæœ‰è‰¾ç‰¹ä¼Šè•¾å¨œï¼Œä¼Šè•¾å¨œæ‰èƒ½æ¥æ”¶åˆ°ä½ çš„æ¶ˆæ¯~ï¼'
        )
        event.reply(msg) 
    
    @staticmethod
    def complete_dau(event):
        """è¡¥å…¨30å¤©å†…çš„DAUæ•°æ®ï¼ˆé™¤äº†ä»Šå¤©ï¼‰"""
        try:
            from function.dau_analytics import get_dau_analytics
            
            dau_analytics = get_dau_analytics()
            today = datetime.datetime.now()
            
            # æ£€æŸ¥30å¤©å†…çš„DAUæ•°æ®ï¼ˆé™¤äº†ä»Šå¤©ï¼‰
            missing_dates = []
            
            for i in range(1, 31):  # ä»æ˜¨å¤©å¼€å§‹ï¼Œæ£€æŸ¥30å¤©
                target_date = today - datetime.timedelta(days=i)
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨DAUæ•°æ®æ–‡ä»¶
                dau_data = dau_analytics.load_dau_data(target_date)
                if not dau_data:
                    missing_dates.append(target_date)
            
            if not missing_dates:
                event.reply(f"<@{event.user_id}>\nâœ… è¿‘30å¤©DAUæ•°æ®å®Œæ•´ï¼Œæ— éœ€è¡¥å…¨ï¼")
                return
            
            # å‘é€å¼€å§‹æ¶ˆæ¯
            event.reply(f"<@{event.user_id}>\nğŸ”§ æ£€æµ‹åˆ°{len(missing_dates)}å¤©çš„DAUæ•°æ®ç¼ºå¤±ï¼Œå¼€å§‹è¡¥å…¨...\nè¯·ç¨ç­‰ï¼Œæ­£åœ¨å¤„ç†ä¸­...")
            
            # å¼€å§‹ç”Ÿæˆç¼ºå¤±çš„DAUæ•°æ®
            generated_count, failed_count = 0, 0
            generated_dates, failed_dates = [], []
            
            for target_date in missing_dates:
                try:
                    success = dau_analytics.manual_generate_dau(target_date)
                    if success:
                        generated_count += 1
                        generated_dates.append(target_date.strftime('%Y-%m-%d'))
                    else:
                        failed_count += 1
                        failed_dates.append(target_date.strftime('%Y-%m-%d'))
                except Exception as e:
                    logger.error(f"ç”ŸæˆDAUæ•°æ®å¤±è´¥ {target_date.strftime('%Y-%m-%d')}: {e}")
                    failed_count += 1
                    failed_dates.append(target_date.strftime('%Y-%m-%d'))
            
            # å‘é€ç»“æœ
            system_plugin._send_dau_complete_result(event, generated_count, failed_count, 
                                                   len(missing_dates), generated_dates, failed_dates)
        except Exception as e:
            logger.error(f'è¡¥å…¨DAUæ•°æ®å¤±è´¥: {e}')
            event.reply(f'<@{event.user_id}>\nâŒ è¡¥å…¨DAUæ•°æ®å¤±è´¥: {str(e)}')
    
    @staticmethod
    def _send_dau_complete_result(event, generated_count, failed_count, total_count, 
                                 generated_dates, failed_dates):
        """å‘é€DAUè¡¥å…¨ç»“æœ"""
        info = [
            f'<@{event.user_id}>',
            f'ğŸ“Š DAUæ•°æ®è¡¥å…¨å®Œæˆï¼',
            f'',
            f'ğŸ“ˆ å¤„ç†ç»“æœ:',
            f'âœ… æˆåŠŸç”Ÿæˆ: {generated_count}å¤©',
            f'âŒ ç”Ÿæˆå¤±è´¥: {failed_count}å¤©',
            f'ğŸ“… æ€»è®¡å¤„ç†: {total_count}å¤©'
        ]
        
        # æ˜¾ç¤ºæˆåŠŸç”Ÿæˆçš„æ—¥æœŸï¼ˆæœ€å¤š5ä¸ªï¼‰
        if generated_dates:
            info.append('')
            info.append('âœ… æ–°ç”Ÿæˆçš„æ—¥æœŸ:')
            display_dates = generated_dates[-5:] if len(generated_dates) > 5 else generated_dates
            for date in display_dates:
                info.append(f'  â€¢ {date}')
            if len(generated_dates) > 5:
                info.append(f'  â€¢ ... ç­‰å…±{len(generated_dates)}ä¸ªæ—¥æœŸ')
        
        # æ˜¾ç¤ºå¤±è´¥çš„æ—¥æœŸ
        if failed_dates:
            info.append('')
            info.append('âŒ ç”Ÿæˆå¤±è´¥çš„æ—¥æœŸ:')
            for date in failed_dates:
                info.append(f'  â€¢ {date}')
        
        # å‘é€æ¶ˆæ¯
        event.reply('\n'.join(info))
    
    @staticmethod
    def clean_historical_data(event):
        """åˆ é™¤å†å²æ•°æ®ï¼š8å¤©ä»¥å¤–çš„æ—¥å¿—è¡¨"""
        try:
            start_time = time.time()
            
            # å‘é€å¼€å§‹æ¸…ç†æ¶ˆæ¯
            event.reply(f"<@{event.user_id}>\nğŸ§¹ å¼€å§‹æ¸…ç†å†å²æ•°æ®ï¼Œè¯·ç¨ç­‰...")
            
            # è·å–æ—¥æœŸ
            today = datetime.datetime.now()
            today_str = today.strftime('%Y%m%d')
            eight_days_ago = today - datetime.timedelta(days=8)
            
            cleanup_results = []
            

            
            # æ¸…ç†æ—¥å¿—è¡¨
            log_result = system_plugin._clean_log_tables(eight_days_ago)
            cleanup_results.append(log_result)
            
            # å‘é€ç»“æœ
            system_plugin._send_cleanup_result(event, cleanup_results, start_time, eight_days_ago)
        except Exception as e:
            logger.error(f'åˆ é™¤å†å²æ•°æ®å¤±è´¥: {e}')
            event.reply(f'<@{event.user_id}>\nâŒ åˆ é™¤å†å²æ•°æ®å¤±è´¥: {str(e)}')
    

    
    @staticmethod 
    def _clean_log_tables(eight_days_ago):
        """æ¸…ç†8å¤©ä»¥å¤–çš„æ—¥å¿—è¡¨"""
        try:
            # æ£€æŸ¥æ—¥å¿—æ•°æ®åº“é…ç½®
            if not LOG_DB_CONFIG.get('enabled', False):
                return "âš ï¸ æ—¥å¿—æ•°æ®åº“æœªå¯ç”¨ï¼Œè·³è¿‡æ—¥å¿—è¡¨æ¸…ç†"
            
            if LogDatabasePool is None:
                return "âŒ æ— æ³•è®¿é—®æ—¥å¿—æ•°æ®åº“ï¼Œè·³è¿‡æ—¥å¿—è¡¨æ¸…ç†"
            
            log_db_pool = LogDatabasePool()
            connection = log_db_pool.get_connection()
            
            if not connection:
                return "âŒ æ— æ³•è¿æ¥åˆ°æ—¥å¿—æ•°æ®åº“"
            
            try:
                deleted_count = system_plugin._delete_old_log_tables(connection, eight_days_ago)
                return f"âœ… æ—¥å¿—è¡¨æ¸…ç†: åˆ é™¤ {deleted_count} å¼ è¡¨"
            finally:
                log_db_pool.release_connection(connection)
                
        except Exception as e:
            logger.error(f"æ¸…ç†æ—¥å¿—è¡¨å¤±è´¥: {e}")
            return f"âŒ æ—¥å¿—è¡¨æ¸…ç†å¤±è´¥: {str(e)}"
    
    @staticmethod
    def _delete_old_log_tables(connection, eight_days_ago):
        """åˆ é™¤æ—§çš„æ—¥å¿—è¡¨"""
        from pymysql.cursors import DictCursor
        cursor = None
        deleted_count = 0
        
        try:
            cursor = connection.cursor(DictCursor)
            
            # è·å–æ‰€æœ‰æ—¥å¿—è¡¨
            cursor.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = DATABASE() 
                AND (table_name LIKE 'Mlog_%_message' 
                     OR table_name LIKE 'Mlog_%_plugin'
                     OR table_name LIKE 'Mlog_%_framework' 
                     OR table_name LIKE 'Mlog_%_error'
                     OR table_name LIKE 'Mlog_%_unmatched')
            """)
            
            log_tables = cursor.fetchall()
            logger.info(f"æ‰¾åˆ° {len(log_tables)} å¼ æ—¥å¿—è¡¨å¾…æ£€æŸ¥")
            
            for table in log_tables:
                if system_plugin._should_delete_table(table, eight_days_ago):
                    table_name = system_plugin._get_table_name(table)
                    if table_name and system_plugin._drop_table(cursor, table_name):
                        deleted_count += 1
            
            if deleted_count > 0:
                connection.commit()
                logger.info(f"å·²æäº¤æ—¥å¿—è¡¨åˆ é™¤æ“ä½œï¼Œå…±åˆ é™¤ {deleted_count} å¼ è¡¨")
                
        except Exception as e:
            logger.error(f"åˆ é™¤æ—¥å¿—è¡¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            if connection:
                connection.rollback()
            raise
        finally:
            if cursor:
                cursor.close()
                
        return deleted_count
    
    @staticmethod
    def _should_delete_table(table, eight_days_ago):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ é™¤è¡¨"""
        table_name = system_plugin._get_table_name(table)
        if not table_name:
            return False
            
        try:
            parts = table_name.split('_')
            if len(parts) < 2:
                return False
                
            date_part = parts[1]  # è·å–YYYYMMDDéƒ¨åˆ†
            
            if len(date_part) != 8 or not date_part.isdigit():
                return False
                
            table_date = datetime.datetime.strptime(date_part, '%Y%m%d')
            return table_date < eight_days_ago
            
        except (IndexError, ValueError) as e:
            logger.warning(f"æ— æ³•è§£æè¡¨åæ—¥æœŸ {table_name}: {e}")
            return False
    
    @staticmethod
    def _get_table_name(table):
        """ä»è¡¨è®°å½•ä¸­è·å–è¡¨å"""
        if not isinstance(table, dict):
            logger.warning(f"è·³è¿‡æ— æ•ˆçš„è¡¨è®°å½•: {table}")
            return None
            
        for key in table.keys():
            if key.lower() == 'table_name':
                return table[key]
        return None
    
    @staticmethod
    def _drop_table(cursor, table_name):
        """åˆ é™¤æŒ‡å®šè¡¨"""
        try:
            drop_sql = f"DROP TABLE IF EXISTS `{table_name}`"
            cursor.execute(drop_sql)
            logger.info(f"åˆ é™¤æ—¥å¿—è¡¨: {table_name}")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤è¡¨ {table_name} å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def _send_cleanup_result(event, cleanup_results, start_time, eight_days_ago):
        """å‘é€æ¸…ç†ç»“æœ"""
        total_time = round((time.time() - start_time) * 1000)
        
        info = [
            f'<@{event.user_id}>',
            f'ğŸ§¹ å†å²æ•°æ®æ¸…ç†å®Œæˆï¼',
            f'',
            f'ğŸ“Š æ¸…ç†ç»“æœ:'
        ]
        
        info.extend(cleanup_results)
        info.extend([
            f'',
            f'ğŸ•’ æ¸…ç†è€—æ—¶: {total_time}ms',
            f'ğŸ“… æ¸…ç†èŒƒå›´: {eight_days_ago.strftime("%Y-%m-%d")}ä¹‹å‰çš„æ—¥å¿—è¡¨'
        ])
        
        event.reply('\n'.join(info)) 