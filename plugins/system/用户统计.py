#!/usr/bin/env python
# -*- coding: utf-8 -*-

from core.plugin.PluginManager import Plugin
from function.db_pool import DatabaseService
import json
import logging
import time
import datetime
from config import LOG_DB_CONFIG
from function.database import USERS_TABLE, GROUPS_TABLE, MEMBERS_TABLE, GROUPS_USERS_TABLE
import traceback
from function.httpx_pool import sync_get
from function.database import Database

import os
import sys
import subprocess
import platform

from function.log_db import LogDatabasePool
from core.plugin.PluginManager import PluginManager

logger = logging.getLogger('user_stats')

class system_plugin(Plugin):
    priority = 10
    _restart_status_checked = False
    
    @classmethod
    def _get_restart_status_file(cls):
        plugin_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.join(plugin_dir, 'data')
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        return os.path.join(data_dir, 'restart_status.json')
    
    @classmethod
    def _check_restart_status(cls):
        restart_status_file = cls._get_restart_status_file()
        if not os.path.exists(restart_status_file):
            return
        
        with open(restart_status_file, 'r', encoding='utf-8') as f:
            restart_data = json.load(f)
        
        if restart_data.get('completed', True):
            return
            
        restart_time = restart_data.get('restart_time')
        message_id = restart_data.get('message_id')
        if not (restart_time and message_id):
            return
            
        start_time = datetime.datetime.fromisoformat(restart_time)
        duration_ms = int((datetime.datetime.now() - start_time).total_seconds() * 1000)
        
        cls._send_restart_complete_message(restart_data.get('user_id'), restart_data.get('group_id'), message_id, duration_ms)
        
        restart_data.update({'completed': True})
        with open(restart_status_file, 'w', encoding='utf-8') as f:
            json.dump(restart_data, f, ensure_ascii=False)
    
    @classmethod
    def _send_restart_complete_message(cls, user_id, group_id, message_id, duration_ms):
        from function.Access import BOTAPI, Json
        import random
        
        payload = {
            "msg_type": 0,
            "msg_seq": random.randint(10000, 999999),
            "content": f'âœ… é‡å¯å®Œæˆï¼\nğŸ•’ è€—æ—¶: {duration_ms}ms',
            "msg_id": message_id
        }
        
        endpoint = f"/v2/groups/{group_id}/messages" if group_id != 'c2c' else f"/v2/users/{user_id}/messages"
        BOTAPI(endpoint, "POST", Json(payload))
    
    @staticmethod
    def mask_id(id_str, mask_char="*"):
        if not id_str or len(id_str) <= 6:
            return id_str
        if len(id_str) <= 3:
            return id_str
        return id_str[:3] + mask_char * 4 + id_str[-3:]
    
    @staticmethod
    def create_buttons(event, button_configs):
        # æŒ‰é’®åŠŸèƒ½å·²ç¦ç”¨
        return None
    
    @staticmethod
    def safe_reply(event, message, buttons=None):
        # å¿½ç•¥æŒ‰é’®å‚æ•°ï¼Œç›´æ¥å‘é€æ¶ˆæ¯
        event.reply(message)
    
    @classmethod
    def get_regex_handlers(cls):
        if not cls._restart_status_checked:
            cls._restart_status_checked = True
            cls._check_restart_status()
        
        return {
            r'^ç”¨æˆ·ç»Ÿè®¡$': {'handler': 'get_stats', 'owner_only': True},
            r'^æˆ‘çš„id$': {'handler': 'getid', 'owner_only': False},
            r'^dau(?:\s+)?(\d{4})?$': {'handler': 'handle_dau', 'owner_only': True},
            r'^è¡¥å…¨dau$': {'handler': 'complete_dau', 'owner_only': True},
            r'^è·å–å…¨éƒ¨æŒ‡ä»¤$': {'handler': 'admin_tools', 'owner_only': True},
            r'^å…³äº$': {'handler': 'about_info', 'owner_only': False},
            r'^åˆ é™¤å†å²æ•°æ®$': {'handler': 'clean_historical_data', 'owner_only': True},
            r'^dm(.+)$': {'handler': 'send_dm', 'owner_only': True},
            r'^é‡å¯$': {'handler': 'restart_bot', 'owner_only': True}
        }
    
    @staticmethod
    def getid(event):
        info_parts = [
            f"ç”¨æˆ·ID: {event.user_id}",
            f"ç¾¤ç»„ID: {event.group_id}"
        ]
        
        event.reply("\n".join(info_parts))
    
    @staticmethod
    def send_dm(event):
        content = event.matches[0] if event.matches and event.matches[0] else ""
        
        if not content.strip():
            event.reply(f"âŒ æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º\nğŸ’¡ ä½¿ç”¨æ ¼å¼ï¼šdm+æ¶ˆæ¯å†…å®¹")
            return
        
        if '\\n' in content or '\\t' in content or '\\r' in content or '\\\\' in content:
            content = content.encode('utf-8').decode('unicode_escape')
        
        event.reply(content)
    
    @classmethod
    def admin_tools(cls, event):
        plugin_manager = PluginManager()
        plugin_manager.load_plugins()
        plugins = list(plugin_manager._plugins.keys())
        
        header = [
            f'ğŸ“‹ æ‰€æœ‰å¯ç”¨æŒ‡ä»¤åˆ—è¡¨',
            f'æ€»æ’ä»¶æ•°: {len(plugins)}ä¸ª'
        ]
        
        code_content = []
        total_commands = 0
        
        for plugin in plugins:
            plugin_name = plugin.__name__
            priority = plugin_manager._plugins[plugin]
            handlers = plugin.get_regex_handlers()
            
            if handlers:
                code_content.append(f'ğŸ”§ æ’ä»¶: {plugin_name} (ä¼˜å…ˆçº§: {priority})')
                commands = []
                
                for pattern, handler_info in handlers.items():
                    total_commands += 1
                    emoji = "ğŸ‘‘" if isinstance(handler_info, dict) and handler_info.get('owner_only', False) else "ğŸ”¹"
                    clean_pattern = pattern.replace('^', '').replace('$', '')
                    commands.append(f"  {emoji} {clean_pattern}")
                
                if commands:
                    code_content.extend(sorted(commands))
                    code_content.append('-' * 30)
        
        code_content.append(f'æ€»å‘½ä»¤æ•°: {total_commands}ä¸ª')
        message = '\n'.join(header) + "\n\n```python\n" + '\n'.join(code_content) + "\n```\n"
        
        event.reply(message)
    
    @classmethod
    def handle_dau(cls, event):
        date_str = event.matches[0] if event.matches and event.matches[0] else None
        
        if date_str:
            cls._handle_specific_date_dau(event, date_str)
        else:
            cls._handle_today_dau(event)
    
    @classmethod
    def _handle_specific_date_dau(cls, event, date_str):
        """å¤„ç†ç‰¹å®šæ—¥æœŸçš„DAUæŸ¥è¯¢"""
        if len(date_str) != 4:
            event.reply("æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨MMDDæ ¼å¼ï¼Œä¾‹å¦‚ï¼šdau0522è¡¨ç¤º5æœˆ22æ—¥")
            return
            
        # æ„å»ºå®Œæ•´æ—¥æœŸï¼ˆå‡è®¾æ˜¯å½“å‰å¹´ä»½ï¼‰
        current_year = datetime.datetime.now().year
        try:
            month = int(date_str[:2])
            day = int(date_str[2:])
            # éªŒè¯æ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
            query_date = datetime.datetime(current_year, month, day)
            
            # å¦‚æœç”Ÿæˆçš„æ—¥æœŸåœ¨æœªæ¥ï¼Œå¯èƒ½æ˜¯å»å¹´çš„æ—¥æœŸ
            if query_date > datetime.datetime.now():
                query_date = datetime.datetime(current_year - 1, month, day)
                
            # å°†æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDDæ ¼å¼
            formatted_date = query_date.strftime('%Y%m%d')
            # è°ƒç”¨é€šç”¨DAUæŸ¥è¯¢æ–¹æ³•
            cls._get_dau_data(event, formatted_date)
        except ValueError:
            event.reply(f"æ— æ•ˆçš„æ—¥æœŸ: {date_str}ï¼Œè¯·ä½¿ç”¨æœ‰æ•ˆçš„æœˆä»½å’Œæ—¥æœŸ")
    
    @classmethod
    def _handle_today_dau(cls, event):
        """å¤„ç†ä»Šæ—¥DAUæŸ¥è¯¢"""
        # è·å–ä»Šå¤©çš„æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDD
        today = datetime.datetime.now()
        today_str = today.strftime('%Y%m%d')
        
        # è·å–æ˜¨å¤©çš„æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDD
        yesterday = today - datetime.timedelta(days=1)
        yesterday_str = yesterday.strftime('%Y%m%d')
        
        # å½“å‰å°æ—¶å’Œåˆ†é’Ÿï¼Œç”¨äºé™åˆ¶æ˜¨å¤©æ•°æ®æŸ¥è¯¢èŒƒå›´
        current_hour = today.hour
        current_minute = today.minute
        
        # è°ƒç”¨é€šç”¨DAUæŸ¥è¯¢æ–¹æ³•ï¼Œæ·»åŠ å¯¹æ¯”å‚æ•°
        cls._get_dau_data(event, today_str, yesterday_str, current_hour, current_minute)
    
    @classmethod
    def _get_dau_data(cls, event, date_str, yesterday_str=None, current_hour=None, current_minute=None):
        """è·å–DAUæ•°æ®"""
        start_time = time.time()
        target_date = datetime.datetime.strptime(date_str, '%Y%m%d')
        today = datetime.datetime.now().date()
        is_today = target_date.date() == today
        
        # å¦‚æœä¸æ˜¯ä»Šæ—¥ï¼Œä¼˜å…ˆå°è¯•ä»æ•°æ®åº“è¯»å–å†å²DAUæ•°æ®
        if not is_today:
            try:
                from function.dau_analytics import get_dau_analytics
                dau_analytics = get_dau_analytics()
                dau_data = dau_analytics.load_dau_data(target_date)
                
                if dau_data:
                    cls._send_dau_from_database(event, dau_data, target_date, start_time)
                    return
            except Exception as e:
                logger.warning(f"å°è¯•ä»æ•°æ®åº“è¯»å–DAUæ•°æ®å¤±è´¥: {e}")
            
            display_date = f"{date_str[4:6]}-{date_str[6:8]}"
            event.reply(
                f"<@{event.user_id}>\n"
                f"âŒ {display_date} çš„DAUæ•°æ®æœªç”Ÿæˆæˆ–æ— è¯¥æ—¥æœŸæ•°æ®\n"
                f"ğŸ’¡ å¯ä»¥å‘é€'è¡¥å…¨dau'å‘½ä»¤è¡¥å…¨DAUè®°å½•"
            )
            return
        
        if not LOG_DB_CONFIG.get('enabled', False):
            event.reply("æ—¥å¿—æ•°æ®åº“æœªå¯ç”¨ï¼Œæ— æ³•è·å–DAUç»Ÿè®¡")
            return
            
        try:
            log_db_pool = LogDatabasePool()
            connection = log_db_pool.get_connection()
            
            if not connection:
                event.reply("æ— æ³•è¿æ¥åˆ°æ—¥å¿—æ•°æ®åº“ï¼Œè¯·ç¨åå†è¯•")
                return
            
            cursor = None
            
            try:
                cursor = connection.cursor()
                # ä½¿ç”¨é…ç½®ä¸­çš„è¡¨å‰ç¼€
                table_prefix = LOG_DB_CONFIG.get('table_prefix', 'Mlog_')
                table_name = f"{table_prefix}{date_str}_message"
                
                check_query = """
                    SELECT COUNT(*) as count 
                    FROM information_schema.tables 
                    WHERE table_schema = DATABASE() 
                    AND table_name = %s
                """
                
                cursor.execute(check_query, (table_name,))
                result = cursor.fetchone()
                if not result or result['count'] == 0:
                    display_date = f"{date_str[4:6]}-{date_str[6:8]}"
                    event.reply(f"è¯¥æ—¥æœŸ({display_date})æ— æ¶ˆæ¯è®°å½•")
                    return
                
                time_condition = ""
                if current_hour is not None and current_minute is not None:
                    time_limit = f"{current_hour:02d}:{current_minute:02d}:00"
                    time_condition = f" WHERE TIME(timestamp) <= '{time_limit}'"
                
                total_messages_query = f"SELECT COUNT(*) as count FROM {table_name}{time_condition}"
                cursor.execute(total_messages_query)
                total_messages_result = cursor.fetchone()
                total_messages = total_messages_result['count'] if total_messages_result else 0
                
                unique_users_query = f"SELECT COUNT(DISTINCT user_id) as count FROM {table_name}{time_condition}"
                unique_users_query += " AND user_id IS NOT NULL AND user_id != ''" if time_condition else " WHERE user_id IS NOT NULL AND user_id != ''"
                cursor.execute(unique_users_query)
                unique_users_result = cursor.fetchone()
                unique_users = unique_users_result['count'] if unique_users_result else 0
                
                unique_groups_query = f"SELECT COUNT(DISTINCT group_id) as count FROM {table_name}{time_condition}"
                unique_groups_query += " AND group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''" if time_condition else " WHERE group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''"
                cursor.execute(unique_groups_query)
                unique_groups_result = cursor.fetchone()
                unique_groups = unique_groups_result['count'] if unique_groups_result else 0
                
                private_messages_query = f"SELECT COUNT(*) as count FROM {table_name}{time_condition}"
                private_messages_query += " AND group_id = 'c2c'" if time_condition else " WHERE group_id = 'c2c'"
                cursor.execute(private_messages_query)
                private_messages_result = cursor.fetchone()
                private_messages = private_messages_result['count'] if private_messages_result else 0
                
                # è·å–æœ€æ´»è·ƒçš„2ä¸ªç¾¤ç»„
                active_groups_query = f"""
                    SELECT group_id, COUNT(*) as msg_count 
                    FROM {table_name}{time_condition}
                    """
                active_groups_query += " AND group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''" if time_condition else " WHERE group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''"
                active_groups_query += """
                    GROUP BY group_id 
                    ORDER BY msg_count DESC 
                    LIMIT 2
                """
                cursor.execute(active_groups_query)
                active_groups_result = cursor.fetchall()
                
                # è·å–æœ€æ´»è·ƒçš„2ä¸ªç”¨æˆ·
                active_users_query = f"""
                    SELECT user_id, COUNT(*) as msg_count 
                    FROM {table_name}{time_condition}
                    """
                active_users_query += " AND user_id IS NOT NULL AND user_id != ''" if time_condition else " WHERE user_id IS NOT NULL AND user_id != ''"
                active_users_query += """
                    GROUP BY user_id 
                    ORDER BY msg_count DESC 
                    LIMIT 2
                """
                cursor.execute(active_users_query)
                active_users_result = cursor.fetchall()
                
                # æŒ‰å°æ—¶ç»Ÿè®¡æ¶ˆæ¯æ•°é‡
                hourly_stats_query = f"""
                    SELECT HOUR(timestamp) as hour, COUNT(*) as count 
                    FROM {table_name}{time_condition} 
                    GROUP BY HOUR(timestamp) 
                    ORDER BY hour
                """
                cursor.execute(hourly_stats_query)
                hourly_stats_result = cursor.fetchall()
                
                # è®¡ç®—æ¯å°æ—¶çš„æ¶ˆæ¯æ•°
                hours_data = {i: 0 for i in range(24)}
                if hourly_stats_result:
                    for row in hourly_stats_result:
                        hour = row['hour']
                        count = row['count']
                        hours_data[hour] = count
                
                # æŸ¥æ‰¾æœ€æ´»è·ƒçš„å°æ—¶
                most_active_hour = max(hours_data.items(), key=lambda x: x[1]) if hours_data else (0, 0)
                
                # è¯»å–DAUè¡¨ä¸­çš„äº‹ä»¶æ•°æ®ï¼ˆä»…é™ä»Šæ—¥ï¼‰
                event_stats = {'group_join_count': 0, 'group_leave_count': 0, 'friend_add_count': 0, 'friend_remove_count': 0}
                if is_today:
                    try:
                        dau_table_name = f"{table_prefix}dau"
                        cursor.execute(f"""
                            SELECT COUNT(*) as count 
                            FROM information_schema.tables 
                            WHERE table_schema = DATABASE() 
                            AND table_name = %s
                        """, (dau_table_name,))
                        dau_table_exists = cursor.fetchone()
                        
                        if dau_table_exists and dau_table_exists['count'] > 0:
                            cursor.execute(f"""
                                SELECT group_join_count, group_leave_count, friend_add_count, friend_remove_count
                                FROM {dau_table_name}
                                WHERE date = %s
                            """, (target_date.strftime('%Y-%m-%d'),))
                            dau_result = cursor.fetchone()
                            
                            if dau_result:
                                event_stats['group_join_count'] = dau_result.get('group_join_count', 0)
                                event_stats['group_leave_count'] = dau_result.get('group_leave_count', 0)
                                event_stats['friend_add_count'] = dau_result.get('friend_add_count', 0)
                                event_stats['friend_remove_count'] = dau_result.get('friend_remove_count', 0)
                    except Exception as e:
                        logger.warning(f"è¯»å–DAUäº‹ä»¶æ•°æ®å¤±è´¥: {e}")
                
                # å°†YYYYMMDDæ ¼å¼è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
                display_date = f"{date_str[4:6]}-{date_str[6:8]}"
                
                # å¦‚æœæœ‰æ˜¨å¤©çš„æ—¥æœŸï¼ŒæŸ¥è¯¢æ˜¨å¤©åŒæ—¶æ®µçš„æ•°æ®è¿›è¡Œå¯¹æ¯”
                yesterday_data = None
                if yesterday_str and current_hour is not None and current_minute is not None:
                    yesterday_table = f"{table_prefix}{yesterday_str}_message"
                    
                    # æ£€æŸ¥æ˜¨å¤©çš„è¡¨æ˜¯å¦å­˜åœ¨
                    cursor.execute(check_query, (yesterday_table,))
                    y_result = cursor.fetchone()
                    
                    if y_result and y_result['count'] > 0:
                        time_limit = f"{current_hour:02d}:{current_minute:02d}:00"
                        y_time_condition = f" WHERE TIME(timestamp) <= '{time_limit}'"
                        
                        # è·å–æ˜¨å¤©åŒæ—¶æ®µçš„åŸºç¡€ç»Ÿè®¡æ•°æ®
                        yesterday_data = {}
                        
                        # æ˜¨å¤©æ€»æ¶ˆæ¯æ•°
                        cursor.execute(f"SELECT COUNT(*) as count FROM {yesterday_table}{y_time_condition}")
                        y_total = cursor.fetchone()
                        yesterday_data['total_messages'] = y_total['count'] if y_total else 0
                        
                        # æ˜¨å¤©æ´»è·ƒç”¨æˆ·æ•°
                        y_users_query = f"SELECT COUNT(DISTINCT user_id) as count FROM {yesterday_table}{y_time_condition}"
                        y_users_query += " AND user_id IS NOT NULL AND user_id != ''"
                        cursor.execute(y_users_query)
                        y_users = cursor.fetchone()
                        yesterday_data['unique_users'] = y_users['count'] if y_users else 0
                        
                        # æ˜¨å¤©æ´»è·ƒç¾¤ç»„æ•°
                        y_groups_query = f"SELECT COUNT(DISTINCT group_id) as count FROM {yesterday_table}{y_time_condition}"
                        y_groups_query += " AND group_id != 'c2c' AND group_id IS NOT NULL AND group_id != ''"
                        cursor.execute(y_groups_query)
                        y_groups = cursor.fetchone()
                        yesterday_data['unique_groups'] = y_groups['count'] if y_groups else 0
                        
                        # æ˜¨å¤©ç§èŠæ¶ˆæ¯æ•°
                        y_private_query = f"SELECT COUNT(*) as count FROM {yesterday_table}{y_time_condition}"
                        y_private_query += " AND group_id = 'c2c'"
                        cursor.execute(y_private_query)
                        y_private = cursor.fetchone()
                        yesterday_data['private_messages'] = y_private['count'] if y_private else 0
                
                # æ„å»ºå“åº”ä¿¡æ¯
                info = [
                    f'<@{event.user_id}>',
                    f'ğŸ“Š {display_date} æ´»è·ƒç»Ÿè®¡' + (f' (æˆªè‡³{current_hour:02d}:{current_minute:02d})' if current_hour is not None else '')
                ]
                
                # æ·»åŠ åŸºæœ¬æ•°æ®ä¸æ˜¨å¤©å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰
                if yesterday_data:
                    y_display_date = f"{yesterday_str[4:6]}-{yesterday_str[6:8]}"
                    
                    # ç”¨æˆ·æ•°å¯¹æ¯”
                    user_diff = unique_users - yesterday_data['unique_users']
                    user_change = f"ğŸ”º{user_diff}" if user_diff > 0 else f"ğŸ”»{abs(user_diff)}" if user_diff < 0 else "â–0"
                    info.append(f'ğŸ‘¤ æ´»è·ƒç”¨æˆ·æ•°: {unique_users} ({user_change})')
                    
                    # ç¾¤ç»„æ•°å¯¹æ¯”
                    group_diff = unique_groups - yesterday_data['unique_groups']
                    group_change = f"ğŸ”º{group_diff}" if group_diff > 0 else f"ğŸ”»{abs(group_diff)}" if group_diff < 0 else "â–0"
                    info.append(f'ğŸ‘¥ æ´»è·ƒç¾¤èŠæ•°: {unique_groups} ({group_change})')
                    
                    # æ¶ˆæ¯æ€»æ•°å¯¹æ¯”
                    msg_diff = total_messages - yesterday_data['total_messages']
                    msg_change = f"ğŸ”º{msg_diff}" if msg_diff > 0 else f"ğŸ”»{abs(msg_diff)}" if msg_diff < 0 else "â–0"
                    info.append(f'ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {total_messages} ({msg_change})')
                    
                    # ç§èŠæ¶ˆæ¯å¯¹æ¯”
                    private_diff = private_messages - yesterday_data['private_messages']
                    private_change = f"ğŸ”º{private_diff}" if private_diff > 0 else f"ğŸ”»{abs(private_diff)}" if private_diff < 0 else "â–0"
                    info.append(f'ğŸ“± ç§èŠæ¶ˆæ¯: {private_messages} ({private_change})')
                else:
                    # æ²¡æœ‰æ˜¨å¤©æ•°æ®æ—¶æ˜¾ç¤ºæ™®é€šæ ¼å¼
                    info.append(f'ğŸ‘¤ æ´»è·ƒç”¨æˆ·æ•°: {unique_users}')
                    info.append(f'ğŸ‘¥ æ´»è·ƒç¾¤èŠæ•°: {unique_groups}')
                    info.append(f'ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {total_messages}')
                    info.append(f'ğŸ“± ç§èŠæ¶ˆæ¯: {private_messages}')
                
                info.append(f'â° æœ€æ´»è·ƒæ—¶æ®µ: {most_active_hour[0]}ç‚¹ ({most_active_hour[1]})')
                
                # æ·»åŠ äº‹ä»¶ç»Ÿè®¡ï¼ˆä»…é™ä»Šæ—¥ï¼‰
                if is_today and event_stats and any(event_stats.values()):
                    info.append(f'ğŸ“ˆ ä»Šæ—¥äº‹ä»¶ç»Ÿè®¡:')
                    group_join = event_stats["group_join_count"]
                    group_leave = event_stats["group_leave_count"]
                    friend_add = event_stats["friend_add_count"] 
                    friend_remove = event_stats["friend_remove_count"]
                    
                    info.append(f'  ğŸ‘¥ åŠ ç¾¤: {group_join} | é€€ç¾¤: {group_leave}')
                    info.append(f'  ğŸ‘¤ åŠ å‹: {friend_add} | åˆ å‹: {friend_remove}')
                    
                    # è®¡ç®—ç¾¤ç»„å’Œå¥½å‹çš„å‡€å¢é•¿
                    group_net = group_join - group_leave
                    friend_net = friend_add - friend_remove
                    info.append(f'  ğŸ“Š ç¾¤ç»„å‡€å¢: {group_net:+d} | å¥½å‹å‡€å¢: {friend_net:+d}')
                
                # æ·»åŠ æœ€æ´»è·ƒç¾¤ç»„ä¿¡æ¯
                if active_groups_result:
                    info.append('ğŸ” æœ€æ´»è·ƒç¾¤ç»„:')
                    idx = 1
                    for group in active_groups_result:
                        group_id = group['group_id']
                        if not group_id:
                            continue  # è·³è¿‡ç©º/None
                        masked_group_id = system_plugin.mask_id(group_id)
                        info.append(f"  {idx}. {masked_group_id} ({group['msg_count']}æ¡)")
                        idx += 1
                
                # æ·»åŠ æœ€æ´»è·ƒç”¨æˆ·ä¿¡æ¯
                if active_users_result:
                    info.append('ğŸ‘‘ æœ€æ´»è·ƒç”¨æˆ·:')
                    idx = 1
                    for user in active_users_result:
                        user_id = user['user_id']
                        if not user_id:
                            continue  # è·³è¿‡ç©º/None
                        masked_user_id = system_plugin.mask_id(user_id)
                        info.append(f"  {idx}. {masked_user_id} ({user['msg_count']}æ¡)")
                        idx += 1
                
                # è®¡ç®—æŸ¥è¯¢è€—æ—¶
                query_time = round((time.time() - start_time) * 1000)
                info.append(f'ğŸ•’ æŸ¥è¯¢è€—æ—¶: {query_time}ms')
                info.append(f'ğŸ“ æ•°æ®æº: å®æ—¶æ•°æ®åº“æŸ¥è¯¢')
                
                # å‘é€æ¶ˆæ¯
                event.reply('\n'.join(info))
                
            finally:
                # ç¡®ä¿å…³é—­æ¸¸æ ‡å’Œé‡Šæ”¾è¿æ¥
                if cursor:
                    cursor.close()
                if connection:
                    log_db_pool.release_connection(connection)
            
        except Exception as e:
            logger.error(f'è·å–DAUç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}')
            event.reply(f'DAUç»Ÿè®¡æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}')
    
    @classmethod
    def _send_dau_from_database(cls, event, dau_data, target_date, start_time):
        """ä»æ•°æ®åº“åŠ è½½DAUæ•°æ®å¹¶å‘é€"""
        try:
            # è·å–æ¶ˆæ¯ç»Ÿè®¡æ•°æ®
            msg_stats = dau_data.get('message_stats', {})
            
            info = [
                f'<@{event.user_id}>',
                f'ğŸ“Š {target_date.strftime("%m-%d")} æ´»è·ƒç»Ÿè®¡'
            ]
            
            # æ·»åŠ åŸºæœ¬æ•°æ®
            info.append(f'ğŸ‘¤ æ´»è·ƒç”¨æˆ·æ•°: {msg_stats.get("active_users", 0)}')
            info.append(f'ğŸ‘¥ æ´»è·ƒç¾¤èŠæ•°: {msg_stats.get("active_groups", 0)}')
            info.append(f'ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {msg_stats.get("total_messages", 0)}')
            info.append(f'ğŸ“± ç§èŠæ¶ˆæ¯: {msg_stats.get("private_messages", 0)}')
            
            # æ·»åŠ æœ€æ´»è·ƒæ—¶æ®µ
            peak_hour = msg_stats.get("peak_hour", 0)
            peak_hour_count = msg_stats.get("peak_hour_count", 0)
            info.append(f'â° æœ€æ´»è·ƒæ—¶æ®µ: {peak_hour}ç‚¹ ({peak_hour_count}æ¡)')
            
            # æ·»åŠ äº‹ä»¶ç»Ÿè®¡æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            event_stats = dau_data.get('event_stats', {})
            if event_stats and any(event_stats.values()):
                info.append(f'ğŸ“ˆ äº‹ä»¶ç»Ÿè®¡:')
                group_join = event_stats.get("group_join_count", 0)
                group_leave = event_stats.get("group_leave_count", 0) 
                friend_add = event_stats.get("friend_add_count", 0)
                friend_remove = event_stats.get("friend_remove_count", 0)
                group_net = group_join - group_leave
                friend_net = friend_add - friend_remove
                info.append(f'  ğŸ‘¥ åŠ ç¾¤: {group_join} | é€€ç¾¤: {group_leave} | å‡€å¢: {group_net:+d}')
                info.append(f'  ğŸ‘¤ åŠ å‹: {friend_add} | åˆ å‹: {friend_remove} | å‡€å¢: {friend_net:+d}')
            
            # æ·»åŠ æœ€æ´»è·ƒç¾¤ç»„ä¿¡æ¯
            top_groups = msg_stats.get("top_groups", [])
            if top_groups:
                info.append('ğŸ” æœ€æ´»è·ƒç¾¤ç»„:')
                idx = 1
                for group in top_groups[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                    group_id = group.get("group_id", "")
                    if not group_id:
                        continue  # è·³è¿‡ç©º/None
                    masked_group_id = system_plugin.mask_id(group_id)
                    info.append(f"  {idx}. {masked_group_id} ({group.get('message_count', 0)}æ¡)")
                    idx += 1
            
            # æ·»åŠ æœ€æ´»è·ƒç”¨æˆ·ä¿¡æ¯
            top_users = msg_stats.get("top_users", [])
            if top_users:
                info.append('ğŸ‘‘ æœ€æ´»è·ƒç”¨æˆ·:')
                idx = 1
                for user in top_users[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                    user_id = user.get("user_id", "")
                    if not user_id:
                        continue  # è·³è¿‡ç©º/None
                    masked_user_id = system_plugin.mask_id(user_id)
                    info.append(f"  {idx}. {masked_user_id} ({user.get('message_count', 0)}æ¡)")
                    idx += 1
            
            # è®¡ç®—æŸ¥è¯¢è€—æ—¶
            query_time = round((time.time() - start_time) * 1000)
            info.append(f'ğŸ•’ æŸ¥è¯¢è€—æ—¶: {query_time}ms')
            info.append(f'ğŸ“ æ•°æ®æº: æ•°æ®åº“')
            
            # æ·»åŠ ç”Ÿæˆæ—¶é—´ä¿¡æ¯
            if dau_data.get('generated_at'):
                try:
                    gen_time = datetime.datetime.fromisoformat(dau_data['generated_at'].replace('Z', '+00:00'))
                    info.append(f'ğŸ•’ æ•°æ®ç”Ÿæˆæ—¶é—´: {gen_time.strftime("%m-%d %H:%M")}')
                except:
                    pass
            
            # å‘é€æ¶ˆæ¯
            event.reply('\n'.join(info))
            
        except Exception as e:
            logger.error(f"å‘é€DAUæ•°æ®åº“æ•°æ®å¤±è´¥: {e}")
            # å¦‚æœè§£ææ•°æ®åº“æ•°æ®å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹é”™è¯¯æ¶ˆæ¯
            event.reply(f"DAUæ•°æ®åº“æ•°æ®è§£æå¤±è´¥: {str(e)}")
    
    @classmethod
    def _get_query_params(cls):
        """è·å–æ‰€æœ‰æŸ¥è¯¢å‚æ•°"""
        return [
            # åŸºç¡€æŸ¥è¯¢
            (f"SELECT COUNT(*) as count FROM {USERS_TABLE}", None, False),  # ç”¨æˆ·æ•°é‡
            (f"SELECT COUNT(*) as count FROM {GROUPS_TABLE}", None, False),  # ç¾¤ç»„æ•°é‡
            (f"SELECT COUNT(*) as count FROM {MEMBERS_TABLE}", None, False),  # ç§èŠç”¨æˆ·æ•°é‡
            # æœ€æ´»è·ƒç¾¤ç»„æŸ¥è¯¢
            (f"""
                SELECT group_id, JSON_LENGTH(users) as member_count
                FROM {GROUPS_USERS_TABLE}
                ORDER BY member_count DESC
                LIMIT 1
            """, None, False),
            # UINç»Ÿè®¡æŸ¥è¯¢ï¼ˆåªä¿ç•™ä¸€ä¸ªå ä½æŸ¥è¯¢ï¼Œå®é™…ä½¿ç”¨å›ºå®šå€¼ï¼‰
            ("SELECT 1 as placeholder", None, False)  # å ä½æŸ¥è¯¢ï¼ŒUINæˆåŠŸæ•°ä½¿ç”¨å›ºå®šå€¼64019
        ]
    
    @classmethod
    def _get_group_info_params(cls, group_id):
        """è·å–æŒ‡å®šç¾¤ç»„çš„æŸ¥è¯¢å‚æ•°"""
        return [
            # ç¾¤æˆå‘˜æ•°é‡
                            (f"SELECT users FROM {GROUPS_USERS_TABLE} WHERE group_id = %s", (group_id,), False),
            # è·å–æ‰€æœ‰ç¾¤ç»„æ•°æ®ï¼Œç”¨äºè®¡ç®—æ’å
            (f"""
                SELECT group_id, JSON_LENGTH(users) as member_count
                FROM {GROUPS_USERS_TABLE}
                ORDER BY member_count DESC
            """, None, True)
        ]
    
    @classmethod
    def _process_result(cls, results):
        """å¤„ç†æŸ¥è¯¢ç»“æœ"""
        user_count = results[0]['count'] if results[0] else 0
        group_count = results[1]['count'] if results[1] else 0
        private_users_count = results[2]['count'] if results[2] else 0
        
        # å¤„ç†æœ€æ´»è·ƒç¾¤ç»„æ•°æ®
        most_active_result = results[3]
        if most_active_result:
            group_id = most_active_result.get('group_id', "æ— æ•°æ®")
            # ä½¿ç”¨ç»Ÿä¸€çš„è„±æ•æ–¹æ³•
            if group_id != "æ— æ•°æ®":
                group_id = system_plugin.mask_id(group_id)
            
            most_active_group = {
                'group_id': group_id,
                'member_count': most_active_result.get('member_count', 0)
            }
        else:
            most_active_group = {'group_id': "æ— æ•°æ®", 'member_count': 0}
            
        # å¤„ç†UINç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨å›ºå®šå€¼ï¼Œä¸ä»æ•°æ®åº“è·å–ï¼‰
        uin_success = 64019  # å›ºå®šå€¼
        
        return {
            'user_count': user_count,
            'group_count': group_count,
            'private_users_count': private_users_count,
            'most_active_group': most_active_group,
            'uin_stats': {
                'success': uin_success
            }
        }
    
    @classmethod
    def _process_group_results(cls, results, group_id):
        """å¤„ç†ç¾¤ç»„ç›¸å…³æŸ¥è¯¢ç»“æœ"""
        # è§£æç¾¤æˆå‘˜æ•°æ®
        group_members = 0
        if results[0] and results[0].get('users'):
            users = results[0]['users']
            if isinstance(users, str):
                users = json.loads(users)
            group_members = len(users)
        
        # è®¡ç®—ç¾¤æ’å
        group_rank = 'N/A'
        if results[1]:
            for i, group in enumerate(results[1], 1):
                if group.get('group_id') == group_id:
                    group_rank = i
                    break
        
        return {
            'member_count': group_members,
            'rank': group_rank
        }
    
    @classmethod
    def get_stats(cls, event):
        """è·å–ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨db_poolçš„å¹¶å‘æŸ¥è¯¢"""
        start_time = time.time()
        
        try:
            db = DatabaseService()
            
            # å‡†å¤‡æ‰€æœ‰æŸ¥è¯¢
            query_params = cls._get_query_params()
            
            # å¦‚æœåœ¨ç¾¤èŠä¸­ï¼Œæ·»åŠ ç¾¤ç»„ç›¸å…³æŸ¥è¯¢
            group_results = None
            if event.group_id:
                group_query_params = cls._get_group_info_params(event.group_id)
                
                # æ‰§è¡Œç¾¤ç»„æŸ¥è¯¢
                group_results = db.execute_concurrent_queries(group_query_params)
            
            # æ‰§è¡ŒåŸºç¡€æŸ¥è¯¢
            results = db.execute_concurrent_queries(query_params)
            
            # å¤„ç†æŸ¥è¯¢ç»“æœ
            stats = cls._process_result(results)
            
            # æ„å»ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            info = [
                f'<@{event.user_id}>',
                f'ğŸ“Š ç»Ÿè®¡ä¿¡æ¯',
            ]
            
            # å¦‚æœåœ¨ç¾¤èŠä¸­ï¼Œé¦–å…ˆæ·»åŠ å½“å‰ç¾¤æˆå‘˜ä¿¡æ¯
            if event.group_id and group_results:
                group_info = cls._process_group_results(group_results, event.group_id)
                info.append(f'ğŸ‘¥ å½“å‰ç¾¤æˆå‘˜: {group_info["member_count"]}')
            
            # æŒ‰ç…§æŒ‡å®šé¡ºåºæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            info.append(f'ğŸ‘¤ å¥½å‹æ€»æ•°é‡: {stats["private_users_count"]}')
            info.append(f'ğŸ‘¥ ç¾¤ç»„æ€»æ•°é‡: {stats["group_count"]}')
            info.append(f'ğŸ‘¥ æ‰€æœ‰ç”¨æˆ·æ€»æ•°é‡: {stats["user_count"]}')
            info.append(f'ğŸ” æœ€å¤§ç¾¤: {stats["most_active_group"]["group_id"]} (ç¾¤å‘˜: {stats["most_active_group"]["member_count"]})')
            
            # æ·»åŠ UINç»Ÿè®¡ä¿¡æ¯ï¼ˆåªæ˜¾ç¤ºæˆåŠŸè·å–æ•°ï¼‰
            info.append(f'âœ… UINæˆåŠŸè·å–: {stats["uin_stats"]["success"]}')
            
            # å¦‚æœåœ¨ç¾¤èŠä¸­ï¼Œæ·»åŠ å½“å‰ç¾¤çš„æ’åä¿¡æ¯
            if event.group_id and group_results:
                group_info = cls._process_group_results(group_results, event.group_id)
                info.append(f'ğŸ“ˆ å½“å‰ç¾¤æ’å: ç¬¬{group_info["rank"]}å')
            
            # ç»Ÿè®¡æŸ¥è¯¢æ—¶é—´
            query_time = round((time.time() - start_time) * 1000)
            info.append(f'ğŸ•’ æŸ¥è¯¢è€—æ—¶: {query_time}ms')
            
            # å‘é€æ¶ˆæ¯
            event.reply('\n'.join(info))
            
        except Exception as e:
            logger.error(f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}')
            event.reply(f'ç»Ÿè®¡æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}')
    
    @staticmethod
    def about_info(event):
        """å…³äºç•Œé¢"""
        try:
            plugin_manager = PluginManager()
            plugin_manager.load_plugins()
            kernel_count = len(plugin_manager._plugins)
            function_count = len(plugin_manager._regex_handlers)
        except:
            kernel_count = "è·å–å¤±è´¥"
            function_count = "è·å–å¤±è´¥"
            
        import platform
        python_version = platform.python_version()
            
        msg = (
f'<@{event.user_id}>å…³äºä¼Šè•¾å¨œ\n___\n'
'ğŸ”Œ è¿æ¥æ–¹å¼: WebHook\n'
'ğŸ¤– æœºå™¨äººQQ: 3889045760\n'
'ğŸ†” æœºå™¨äººappid: 102134274\n'
'ğŸš€ å†…æ ¸ç‰ˆæœ¬ï¼šElaina 1.2.3\n'
'ğŸ—ï¸ è¿æ¥Botæ¡†æ¶: Elaina-Mbot\n'
f'âš™ï¸ Pythonç‰ˆæœ¬: {python_version}\n'
f'ğŸ’« å·²åŠ è½½å†…æ ¸æ•°: {kernel_count}\n'
f'âš¡ å·²åŠ è½½å¤„ç†å™¨æ•°: {function_count}\n'
'\n\n>Tip:åªæœ‰è‰¾ç‰¹ä¼Šè•¾å¨œï¼Œä¼Šè•¾å¨œæ‰èƒ½æ¥æ”¶åˆ°ä½ çš„æ¶ˆæ¯~ï¼'
        )
        system_plugin.safe_reply(event, msg) 
    
    @staticmethod
    def complete_dau(event):
        from function.dau_analytics import get_dau_analytics
        
        dau_analytics = get_dau_analytics()
        today = datetime.datetime.now()
        
        missing_dates = []
        for i in range(1, 31):
            target_date = today - datetime.timedelta(days=i)
            dau_data = dau_analytics.load_dau_data(target_date)
            if not dau_data:
                missing_dates.append(target_date)
        
        if not missing_dates:
            event.reply(f"âœ… è¿‘30å¤©DAUæ•°æ®å®Œæ•´ï¼Œæ— éœ€è¡¥å…¨ï¼")
            return
        
        event.reply(f"ğŸ”§ æ£€æµ‹åˆ°{len(missing_dates)}å¤©çš„DAUæ•°æ®ç¼ºå¤±ï¼Œå¼€å§‹è¡¥å…¨...")
        
        generated_count, failed_count = 0, 0
        generated_dates, failed_dates = [], []
        
        for target_date in missing_dates:
            success = dau_analytics.manual_generate_dau(target_date)
            if success:
                generated_count += 1
                generated_dates.append(target_date.strftime('%Y-%m-%d'))
            else:
                failed_count += 1
                failed_dates.append(target_date.strftime('%Y-%m-%d'))
        
        system_plugin._send_dau_complete_result(event, generated_count, failed_count, 
                                               len(missing_dates), generated_dates, failed_dates)
    
    @staticmethod
    def _send_dau_complete_result(event, generated_count, failed_count, total_count, 
                                 generated_dates, failed_dates):
        """å‘é€DAUè¡¥å…¨ç»“æœ"""
        info = [
            f'<@{event.user_id}>',
            f'ğŸ“Š DAUæ•°æ®è¡¥å…¨å®Œæˆï¼',
            f'',
            f'ğŸ“ˆ å¤„ç†ç»“æœ:',
            f'âœ… æˆåŠŸç”Ÿæˆ: {generated_count}å¤©',
            f'âŒ ç”Ÿæˆå¤±è´¥: {failed_count}å¤©',
            f'ğŸ“… æ€»è®¡å¤„ç†: {total_count}å¤©'
        ]
        
        # æ˜¾ç¤ºæˆåŠŸç”Ÿæˆçš„æ—¥æœŸï¼ˆæœ€å¤š5ä¸ªï¼‰
        if generated_dates:
            info.append('')
            info.append('âœ… æ–°ç”Ÿæˆçš„æ—¥æœŸ:')
            display_dates = generated_dates[-5:] if len(generated_dates) > 5 else generated_dates
            for date in display_dates:
                info.append(f'  â€¢ {date}')
            if len(generated_dates) > 5:
                info.append(f'  â€¢ ... ç­‰å…±{len(generated_dates)}ä¸ªæ—¥æœŸ')
        
        # æ˜¾ç¤ºå¤±è´¥çš„æ—¥æœŸ
        if failed_dates:
            info.append('')
            info.append('âŒ ç”Ÿæˆå¤±è´¥çš„æ—¥æœŸ:')
            for date in failed_dates:
                info.append(f'  â€¢ {date}')
        
        # å‘é€æ¶ˆæ¯
        event.reply('\n'.join(info))
    
    @staticmethod
    def clean_historical_data(event):
        """åˆ é™¤å†å²æ•°æ®ï¼š8å¤©ä»¥å¤–çš„æ—¥å¿—è¡¨"""
        try:
            start_time = time.time()
            
            # å‘é€å¼€å§‹æ¸…ç†æ¶ˆæ¯
            event.reply(f"<@{event.user_id}>\nğŸ§¹ å¼€å§‹æ¸…ç†å†å²æ•°æ®ï¼Œè¯·ç¨ç­‰...")
            
            # è·å–æ—¥æœŸ
            today = datetime.datetime.now()
            today_str = today.strftime('%Y%m%d')
            eight_days_ago = today - datetime.timedelta(days=8)
            
            cleanup_results = []
            

            
            # æ¸…ç†æ—¥å¿—è¡¨
            log_result = system_plugin._clean_log_tables(eight_days_ago)
            cleanup_results.append(log_result)
            
            # å‘é€ç»“æœ
            system_plugin._send_cleanup_result(event, cleanup_results, start_time, eight_days_ago)
        except Exception as e:
            logger.error(f'åˆ é™¤å†å²æ•°æ®å¤±è´¥: {e}')
            event.reply(f'<@{event.user_id}>\nâŒ åˆ é™¤å†å²æ•°æ®å¤±è´¥: {str(e)}')
    

    
    @staticmethod 
    def _clean_log_tables(eight_days_ago):
        """æ¸…ç†8å¤©ä»¥å¤–çš„æ—¥å¿—è¡¨"""
        try:
            # æ£€æŸ¥æ—¥å¿—æ•°æ®åº“é…ç½®
            if not LOG_DB_CONFIG.get('enabled', False):
                return "âš ï¸ æ—¥å¿—æ•°æ®åº“æœªå¯ç”¨ï¼Œè·³è¿‡æ—¥å¿—è¡¨æ¸…ç†"
            
            log_db_pool = LogDatabasePool()
            connection = log_db_pool.get_connection()
            
            if not connection:
                return "âŒ æ— æ³•è¿æ¥åˆ°æ—¥å¿—æ•°æ®åº“"
            
            try:
                deleted_count = system_plugin._delete_old_log_tables(connection, eight_days_ago)
                return f"âœ… æ—¥å¿—è¡¨æ¸…ç†: åˆ é™¤ {deleted_count} å¼ è¡¨"
            finally:
                log_db_pool.release_connection(connection)
                
        except Exception as e:
            logger.error(f"æ¸…ç†æ—¥å¿—è¡¨å¤±è´¥: {e}")
            return f"âŒ æ—¥å¿—è¡¨æ¸…ç†å¤±è´¥: {str(e)}"
    
    @staticmethod
    def _delete_old_log_tables(connection, eight_days_ago):
        """åˆ é™¤æ—§çš„æ—¥å¿—è¡¨"""
        from pymysql.cursors import DictCursor
        cursor = None
        deleted_count = 0
        
        try:
            cursor = connection.cursor(DictCursor)
            
            # è·å–é…ç½®ä¸­çš„è¡¨å‰ç¼€
            table_prefix = LOG_DB_CONFIG.get('table_prefix', 'Mlog_')
            
            # è·å–æ‰€æœ‰æ—¥å¿—è¡¨
            cursor.execute(f"""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = DATABASE() 
                AND (table_name LIKE '{table_prefix}%_message' 
                     OR table_name LIKE '{table_prefix}%_plugin'
                     OR table_name LIKE '{table_prefix}%_framework' 
                     OR table_name LIKE '{table_prefix}%_error'
                     OR table_name LIKE '{table_prefix}%_unmatched')
            """)
            
            log_tables = cursor.fetchall()
            logger.info(f"æ‰¾åˆ° {len(log_tables)} å¼ æ—¥å¿—è¡¨å¾…æ£€æŸ¥")
            
            for table in log_tables:
                if system_plugin._should_delete_table(table, eight_days_ago):
                    table_name = system_plugin._get_table_name(table)
                    if table_name and system_plugin._drop_table(cursor, table_name):
                        deleted_count += 1
            
            if deleted_count > 0:
                connection.commit()
                logger.info(f"å·²æäº¤æ—¥å¿—è¡¨åˆ é™¤æ“ä½œï¼Œå…±åˆ é™¤ {deleted_count} å¼ è¡¨")
                
        except Exception as e:
            logger.error(f"åˆ é™¤æ—¥å¿—è¡¨è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            if connection:
                connection.rollback()
            raise
        finally:
            if cursor:
                cursor.close()
                
        return deleted_count
    
    @staticmethod
    def _should_delete_table(table, eight_days_ago):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ é™¤è¡¨"""
        table_name = system_plugin._get_table_name(table)
        if not table_name:
            return False
            
        try:
            # è·å–é…ç½®ä¸­çš„è¡¨å‰ç¼€
            table_prefix = LOG_DB_CONFIG.get('table_prefix', 'Mlog_')
            
            # æ£€æŸ¥è¡¨åæ˜¯å¦ä»¥é…ç½®çš„å‰ç¼€å¼€å§‹
            if not table_name.startswith(table_prefix):
                return False
                
            # ç§»é™¤å‰ç¼€åè·å–å‰©ä½™éƒ¨åˆ†
            remaining_part = table_name[len(table_prefix):]
            parts = remaining_part.split('_')
            
            if len(parts) < 2:
                return False
                
            date_part = parts[0]  # è·å–YYYYMMDDéƒ¨åˆ†
            
            if len(date_part) != 8 or not date_part.isdigit():
                return False
                
            table_date = datetime.datetime.strptime(date_part, '%Y%m%d')
            return table_date < eight_days_ago
            
        except (IndexError, ValueError) as e:
            logger.warning(f"æ— æ³•è§£æè¡¨åæ—¥æœŸ {table_name}: {e}")
            return False
    
    @staticmethod
    def _get_table_name(table):
        """ä»è¡¨è®°å½•ä¸­è·å–è¡¨å"""
        if not isinstance(table, dict):
            logger.warning(f"è·³è¿‡æ— æ•ˆçš„è¡¨è®°å½•: {table}")
            return None
            
        for key in table.keys():
            if key.lower() == 'table_name':
                return table[key]
        return None
    
    @staticmethod
    def _drop_table(cursor, table_name):
        """åˆ é™¤æŒ‡å®šè¡¨"""
        try:
            drop_sql = f"DROP TABLE IF EXISTS `{table_name}`"
            cursor.execute(drop_sql)
            logger.info(f"åˆ é™¤æ—¥å¿—è¡¨: {table_name}")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤è¡¨ {table_name} å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def _send_cleanup_result(event, cleanup_results, start_time, eight_days_ago):
        """å‘é€æ¸…ç†ç»“æœ"""
        total_time = round((time.time() - start_time) * 1000)
        
        info = [
            f'<@{event.user_id}>',
            f'ğŸ§¹ å†å²æ•°æ®æ¸…ç†å®Œæˆï¼',
            f'',
            f'ğŸ“Š æ¸…ç†ç»“æœ:'
        ]
        
        info.extend(cleanup_results)
        info.extend([
            f'',
            f'ğŸ•’ æ¸…ç†è€—æ—¶: {total_time}ms',
            f'ğŸ“… æ¸…ç†èŒƒå›´: {eight_days_ago.strftime("%Y-%m-%d")}ä¹‹å‰çš„æ—¥å¿—è¡¨'
        ])
        
        event.reply('\n'.join(info))
    
    @staticmethod
    def restart_bot(event):
        current_pid = os.getpid()
        current_dir = os.getcwd()
        main_py_path = os.path.join(current_dir, 'main.py')
        
        if not os.path.exists(main_py_path):
            event.reply('âŒ main.pyæ–‡ä»¶ä¸å­˜åœ¨ï¼')
            return
        
        event.reply('ğŸ”„ æ­£åœ¨é‡å¯æœºå™¨äºº...\nâ±ï¸ é¢„è®¡é‡å¯æ—¶é—´: 1ç§’')
        
        restart_status = {
            'restart_time': datetime.datetime.now().isoformat(),
            'completed': False,
            'message_id': event.message_id,
            'user_id': event.user_id,
            'group_id': event.group_id if event.is_group else 'c2c'
        }
        
        restart_status_file = system_plugin._get_restart_status_file()
        with open(restart_status_file, 'w', encoding='utf-8') as f:
            json.dump(restart_status, f, ensure_ascii=False)
        
        restart_script_content = system_plugin._create_restart_python_script(current_pid, main_py_path)
        restart_script_path = os.path.join(current_dir, 'bot_restarter.py')
        
        with open(restart_script_path, 'w', encoding='utf-8') as f:
            f.write(restart_script_content)
        
        is_windows = platform.system().lower() == 'windows'
        
        if is_windows:
            subprocess.Popen(['python', restart_script_path], cwd=current_dir,
                           creationflags=subprocess.CREATE_NEW_CONSOLE)
        else:
            subprocess.Popen([sys.executable, restart_script_path], cwd=current_dir,
                           start_new_session=True)
    
    @staticmethod
    def _create_restart_python_script(current_pid, main_py_path):
        script_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import signal
import platform
import subprocess

def main():
    current_pid = {current_pid}
    main_py_path = r"{main_py_path}"
    try:
        if platform.system().lower() == 'windows':
            subprocess.run(['taskkill', '/PID', str(current_pid), '/F'], 
                         check=False, capture_output=True)
        else:
            try:
                os.kill(current_pid, signal.SIGTERM)
                time.sleep(0.1)
                try:
                    os.kill(current_pid, signal.SIGKILL)
                except ProcessLookupError:
                    pass
            except ProcessLookupError:
                pass
    except Exception as e:
        pass
    
    time.sleep(0.1)
    try:
        os.chdir(os.path.dirname(main_py_path))
        
        if platform.system().lower() == 'windows':
            subprocess.Popen(
                [sys.executable, main_py_path],
                creationflags=subprocess.CREATE_NEW_CONSOLE,
                cwd=os.path.dirname(main_py_path)
            )
        else:
            try:
                script_path = __file__
                if os.path.exists(script_path):
                    os.remove(script_path)
            except:
                pass
            os.execv(sys.executable, [sys.executable, main_py_path])
        
    except Exception as e:
        sys.exit(1)
    
    if platform.system().lower() == 'windows':
        time.sleep(0.1)
        try:
            script_path = __file__
            if os.path.exists(script_path):
                os.remove(script_path)
        except:
            pass
        sys.exit(0)

if __name__ == "__main__":
    main()
'''
        return script_content
    
 